{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0182193a-0156-43f7-96cb-0d6012e4575a",
   "metadata": {
    "tags": []
   },
   "source": [
    "<B><h1><font color = \"green\" size = '20'>HANDOUT ASSIGNMENTS : </font></h1></B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d96150c-19aa-4207-a097-56ab1dc2def0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete\n"
     ]
    }
   ],
   "source": [
    "# YOU HAVE TO RUN THIS CODE EVERYTIME YOU RESTART THE KERNEL\n",
    "from checker.assignment1 import Solution\n",
    "#Enter your name in quotes with underscore for space below\n",
    "sol = Solution('vivek_agarwal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d56c48-ff63-4839-b4fb-4370532f1515",
   "metadata": {},
   "source": [
    "<h1><B><font color = 'red'>GPU OPTIMISATION</font><B></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d9e6a5-f38e-4377-8cbd-d3f998813c2f",
   "metadata": {},
   "source": [
    "# In the below question, we want you to make some changes, so that m1, m2, product are all on the GPU \n",
    "\n",
    "# You can run the cell containing checker code to see whether you succeeded or not.\n",
    "Note : You may have to restart the kernel everytime you change the GPU, the kernel restart option is available under the kernel menu in top left.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d092a609-f262-4c01-bca8-0476256ec5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "## CHANGE BELOW CODE\n",
    "\n",
    "with tf.device('/gpu:1'):\n",
    "    m1 = tf.constant([[3., 5.]])\n",
    "    m2 = tf.constant([[2.],[4.]])\n",
    "\n",
    "    product = tf.matmul(m1, m2)    # A matrix multiplication op node\n",
    "\n",
    "\n",
    "## CHANGE ABOVE CODE\n",
    "sess = tf.Session()\n",
    "\n",
    "print(product.device)\n",
    "print(m1.device)\n",
    "print(m2.device)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1852fdae-15f2-4ddb-b59e-16028fbd2d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sol.q1_check(m1,m2,product) #RUN THIS CELL WITHOUT CHANGE TO SEE YOUR SCORE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c86993-11a8-4fd9-8af7-fc97a79251f4",
   "metadata": {},
   "source": [
    "# In the next task, we are providing you a boiler plate code based on Model Parallelism. \n",
    "You have to complete the following task in your code:\n",
    "We have already initialised two matrix of dimension 2X2, a and b, with random values.\n",
    "Now you have to implement this three steps.\n",
    "\n",
    "\n",
    "1.   Use gpu with id '0' to perform matrix multiplication and append it in  the list 'c'.\n",
    "2.  Use gpu with id '1' to perform atrix multiplication of 'a' and 'b'. And append it in list 'c'.\n",
    "3.  Add all the matrix which you appended in list 'c' above and store result in sum. You have to use cpu with id '0' for this step.\n",
    "\n",
    "In case the gpus are not available, you can try in other gpus (id 0-4), just make sure both gpus are not the same.\n",
    "\n",
    "### Reminder: you may have to restart kernel everytime you change gpus/cpus in code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba44adb5-0007-4122-ba02-23fb927a5693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_30684/3553532152.py:7: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_30684/3553532152.py:30: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-19 19:46:43.167836: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-08-19 19:46:43.199609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:04:00.0\n",
      "2021-08-19 19:46:43.202010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:05:00.0\n",
      "2021-08-19 19:46:43.203317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 2 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:08:00.0\n",
      "2021-08-19 19:46:43.204357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 3 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:09:00.0\n",
      "2021-08-19 19:46:43.206657: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 4 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:89:00.0\n",
      "2021-08-19 19:46:43.207369: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-08-19 19:46:43.210830: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-08-19 19:46:43.213774: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-08-19 19:46:43.214524: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-08-19 19:46:43.218340: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-08-19 19:46:43.221278: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-08-19 19:46:43.229219: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-08-19 19:46:43.243129: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1, 2, 3, 4\n",
      "2021-08-19 19:46:43.244424: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2021-08-19 19:46:43.259028: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1700085000 Hz\n",
      "2021-08-19 19:46:43.261304: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56372b823f60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-08-19 19:46:43.261340: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_30684/3553532152.py:32: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-19 19:46:44.015051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:04:00.0\n",
      "2021-08-19 19:46:44.016575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:05:00.0\n",
      "2021-08-19 19:46:44.017381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 2 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:08:00.0\n",
      "2021-08-19 19:46:44.018200: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 3 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:09:00.0\n",
      "2021-08-19 19:46:44.019678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 4 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:89:00.0\n",
      "2021-08-19 19:46:44.019751: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-08-19 19:46:44.019778: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-08-19 19:46:44.019801: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-08-19 19:46:44.019822: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-08-19 19:46:44.019844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-08-19 19:46:44.019865: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-08-19 19:46:44.019887: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-08-19 19:46:44.032560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1, 2, 3, 4\n",
      "2021-08-19 19:46:44.032634: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-08-19 19:46:44.038492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-08-19 19:46:44.038519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 2 3 4 \n",
      "2021-08-19 19:46:44.038536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N Y Y Y N \n",
      "2021-08-19 19:46:44.038545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   Y N Y Y N \n",
      "2021-08-19 19:46:44.038554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 2:   Y Y N Y N \n",
      "2021-08-19 19:46:44.038562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 3:   Y Y Y N N \n",
      "2021-08-19 19:46:44.038573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 4:   N N N N N \n",
      "2021-08-19 19:46:44.047992: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 84 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1)\n",
      "2021-08-19 19:46:44.051730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10048 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:05:00.0, compute capability: 6.1)\n",
      "2021-08-19 19:46:44.053636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 48 MB memory) -> physical GPU (device: 2, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:08:00.0, compute capability: 6.1)\n",
      "2021-08-19 19:46:44.055986: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 41 MB memory) -> physical GPU (device: 3, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:09:00.0, compute capability: 6.1)\n",
      "2021-08-19 19:46:44.059783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:4 with 10229 MB memory) -> physical GPU (device: 4, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:89:00.0, compute capability: 6.1)\n",
      "2021-08-19 19:46:44.065055: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56372d3241f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2021-08-19 19:46:44.065086: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2021-08-19 19:46:44.065097: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2021-08-19 19:46:44.065106: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2021-08-19 19:46:44.065114: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2021-08-19 19:46:44.065124: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (4): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2021-08-19 19:46:44.765645: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.44637102  0.70501   ]\n",
      " [ 0.31771913 -0.92696714]]\n",
      "/device:GPU:0\n",
      "/device:GPU:1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# list 'c' in which we will append our list\n",
    "c = []\n",
    "# random initialisation of two matrices 'a' and 'b'.\n",
    "a = tf.get_variable(f\"a\", [2, 2], initializer=tf.random_uniform_initializer(-1, 1))\n",
    "b = tf.get_variable(f\"b\", [2, 2], initializer=tf.random_uniform_initializer(-1, 1))\n",
    "\n",
    "##### START CODE HERE  #######\n",
    "\n",
    "'''\n",
    "HINTS :\n",
    "You have to initialise three devices as asked above (gpu-0, gpu-1, cpu-0).\n",
    "After initialisation perform the task in each f those initialisation.\n",
    "For matrix multiplication, look at above task.\n",
    "While for addition part - Find Yourself.\n",
    "'''\n",
    "\n",
    "for i, d in enumerate(['/gpu:0','/gpu:1']):\n",
    "    with tf.device(d):\n",
    "        c.append(tf.matmul(a,b))\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    sum=tf.add_n(c)\n",
    "#### YOU CODE ENDS HERE   ######\n",
    "\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "print(sess.run(sum))\n",
    "print(c[0].device)\n",
    "print(c[1].device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8424057e-ffb9-4acf-b058-0d7f318e0857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct!\n",
      "Your score is now 2\n"
     ]
    }
   ],
   "source": [
    "sol.q2_check(c)  #RUn THIS CELL TO SEE IF YOU ARE CORRECT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc303a6-1b21-46d8-bd13-7e56bd19121b",
   "metadata": {},
   "source": [
    "# Now in this task you will be dealing with Data Parallelism\n",
    "We have declared two tensors a and b, you just have to complete the code so that the matrix multiplication is done in two GPUs with different set of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "982ae848-3ef5-4a06-b46a-9e2ce6d03d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_30819/2862499148.py:6: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_30819/2862499148.py:17: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-19 19:50:15.087934: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-08-19 19:50:15.118805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:04:00.0\n",
      "2021-08-19 19:50:15.120560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:05:00.0\n",
      "2021-08-19 19:50:15.121616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 2 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:08:00.0\n",
      "2021-08-19 19:50:15.122417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 3 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:09:00.0\n",
      "2021-08-19 19:50:15.124181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 4 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:89:00.0\n",
      "2021-08-19 19:50:15.124728: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-08-19 19:50:15.127240: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-08-19 19:50:15.129559: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-08-19 19:50:15.130148: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-08-19 19:50:15.133082: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-08-19 19:50:15.135377: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-08-19 19:50:15.141938: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-08-19 19:50:15.154458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1, 2, 3, 4\n",
      "2021-08-19 19:50:15.155509: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2021-08-19 19:50:15.167956: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1700085000 Hz\n",
      "2021-08-19 19:50:15.170004: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a19f78f8f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-08-19 19:50:15.170035: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_30819/2862499148.py:19: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-19 19:50:15.933104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:04:00.0\n",
      "2021-08-19 19:50:15.936634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:05:00.0\n",
      "2021-08-19 19:50:15.937441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 2 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:08:00.0\n",
      "2021-08-19 19:50:15.938239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 3 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:09:00.0\n",
      "2021-08-19 19:50:15.939708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 4 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:89:00.0\n",
      "2021-08-19 19:50:15.939781: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-08-19 19:50:15.939808: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-08-19 19:50:15.939830: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-08-19 19:50:15.939850: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-08-19 19:50:15.939871: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-08-19 19:50:15.939891: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-08-19 19:50:15.939913: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-08-19 19:50:15.950036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1, 2, 3, 4\n",
      "2021-08-19 19:50:15.950100: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-08-19 19:50:15.958013: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-08-19 19:50:15.958046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 2 3 4 \n",
      "2021-08-19 19:50:15.958064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N Y Y Y N \n",
      "2021-08-19 19:50:15.958073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   Y N Y Y N \n",
      "2021-08-19 19:50:15.958085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 2:   Y Y N Y N \n",
      "2021-08-19 19:50:15.958093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 3:   Y Y Y N N \n",
      "2021-08-19 19:50:15.958101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 4:   N N N N N \n",
      "2021-08-19 19:50:15.965050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 84 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1)\n",
      "2021-08-19 19:50:15.968369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10048 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:05:00.0, compute capability: 6.1)\n",
      "2021-08-19 19:50:15.970746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 48 MB memory) -> physical GPU (device: 2, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:08:00.0, compute capability: 6.1)\n",
      "2021-08-19 19:50:15.973108: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 41 MB memory) -> physical GPU (device: 3, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:09:00.0, compute capability: 6.1)\n",
      "2021-08-19 19:50:15.978264: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:4 with 10229 MB memory) -> physical GPU (device: 4, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:89:00.0, compute capability: 6.1)\n",
      "2021-08-19 19:50:15.983110: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a1a128fc00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2021-08-19 19:50:15.983140: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2021-08-19 19:50:15.983151: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2021-08-19 19:50:15.983161: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2021-08-19 19:50:15.983169: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2021-08-19 19:50:15.983178: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (4): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2021-08-19 19:50:16.663484: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.18842223  0.2776428 ]\n",
      " [ 0.830483    0.5829097 ]\n",
      " [-0.74213207  0.4615608 ]\n",
      " [-0.59943664  1.2275276 ]]\n",
      "/device:GPU:0\n",
      "/device:GPU:1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "c = []\n",
    "a = tf.get_variable(f\"a\", [2, 4, 3], initializer=tf.random_uniform_initializer(-1, 1))  # [2,2,3]\n",
    "b = tf.get_variable(f\"b\", [2, 3, 2], initializer=tf.random_uniform_initializer(-1, 1))\n",
    "\n",
    "# Multiple towers\n",
    "for i, d in enumerate(['/gpu:0' ,'/gpu:1']):   # Complete Code.\n",
    "    with tf.device(d):                        #Complete Code\n",
    "        c.append(tf.matmul(a[i], b[i]))   # Tower i is responsible for batch data i.\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    sum = tf.add_n(c)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "print(sess.run(sum))   \n",
    "print(c[0].device)\n",
    "print(c[1].device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "498e9a30-bc17-4df2-a626-c5b35f73a16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct!\n",
      "Your score is now 3\n"
     ]
    }
   ],
   "source": [
    "sol.q3_check(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98483dbb-9c12-4c5c-8af1-e0449484f702",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "# <font color = \"red\">PANDARALLEL</font>\n",
    "In this part we practice with the pandarallel library that allows parallel processing of DataFrames. \n",
    "\n",
    "#### Note: pandarallel can speed up computation using the physical cores present, hyperthreading does not increase speed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e147c359-188a-47ca-8ca9-ce4712075566",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Run this code before attempting the excerise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2513006e-92ad-4296-a2c6-dc706ce46051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XCoordinate</th>\n",
       "      <th>YCoordinate</th>\n",
       "      <th>Color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.161170</td>\n",
       "      <td>0.369050</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.121162</td>\n",
       "      <td>-0.555671</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.372418</td>\n",
       "      <td>-0.347107</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.644181</td>\n",
       "      <td>-0.476567</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.142344</td>\n",
       "      <td>0.483532</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   XCoordinate  YCoordinate  Color\n",
       "0    -0.161170     0.369050   Blue\n",
       "1    -0.121162    -0.555671    Red\n",
       "2     0.372418    -0.347107  Green\n",
       "3    -0.644181    -0.476567   Blue\n",
       "4    -0.142344     0.483532   Blue"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "\n",
    "tqdm.pandas()\n",
    "size = int(5e6)\n",
    "\n",
    "# Synthetic dataset of random points\n",
    "df = pd.DataFrame({\n",
    "    'XCoordinate': np.random.randn(size),\n",
    "    'YCoordinate': np.random.randn(size),\n",
    "    'Color': np.random.choice(['Red','Blue','Green'],size)\n",
    "})\n",
    "# Preview of dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b57ba2e-d44e-451b-8668-7132c4a11c94",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "For starters you have to first import the `pandarallel` class from the pandarallel module and run the `initialize()` method of the class. You can pass `progress_bar=True` to `initialize()` if you want to see progress bars.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0baac3c1-f93e-406b-91e3-c4c528706247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 16 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "pandarallel.initialize(progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "870559f6-a74a-4026-b17a-eeac22697bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct!\n",
      "Your score is now 4\n"
     ]
    }
   ],
   "source": [
    "sol.q4_check(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40b72ce-52a4-4f84-8675-871719cde59f",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "We have defined the function `l1_norm` here that takes a row in the `DataFrame` as argument and returns the L1 Norm of the point, i.e sum of absolute values of the coordinates. Run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6ce0f37-b10a-44fc-bda2-1cfdd49740ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_norm(row):\n",
    "      return row.XCoordinate + row.YCoordinate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be387d1b-eae8-452c-b5e7-c297f4754c12",
   "metadata": {},
   "source": [
    "Next we will apply the function to each row by calling the `progress_apply()` method on the `DataFrame`. This may take a minute or two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf41df2e-a514-48ef-aadd-d1ab678da9e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a9cfc62627478da311418ba28989c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164.93661165237427\n",
      "CPU times: user 2min 43s, sys: 2.95 s, total: 2min 46s\n",
      "Wall time: 2min 44s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XCoordinate</th>\n",
       "      <th>YCoordinate</th>\n",
       "      <th>Color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.179186</td>\n",
       "      <td>1.137773</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.255866</td>\n",
       "      <td>1.174124</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.321381</td>\n",
       "      <td>0.200504</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.100607</td>\n",
       "      <td>-1.810836</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.514780</td>\n",
       "      <td>-0.940888</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   XCoordinate  YCoordinate  Color\n",
       "0     1.179186     1.137773   Blue\n",
       "1     1.255866     1.174124   Blue\n",
       "2    -0.321381     0.200504  Green\n",
       "3     1.100607    -1.810836    Red\n",
       "4     0.514780    -0.940888    Red"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "seq_time = time.time()\n",
    "\n",
    "seq = df.progress_apply(l1_norm,axis=1)\n",
    "\n",
    "seq_time = time.time() - seq_time\n",
    "print(seq_time)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7c402b-ed7d-4b26-a644-0b62bbdc9b2d",
   "metadata": {},
   "source": [
    "Now your task is to process each row with the same function but now \n",
    "\n",
    "using parallel processing provided with the help of `pandarallel` . You can compre the time with the previous execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a43b6405-8ccc-4488-b699-c9f5f8a333d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b62d77421a09489893d7205e8f1abdea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=312500), Label(value='0 / 312500')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.60965633392334\n",
      "CPU times: user 4.04 s, sys: 932 ms, total: 4.97 s\n",
      "Wall time: 25.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.207880\n",
       "1   -0.676833\n",
       "2    0.025311\n",
       "3   -1.120749\n",
       "4    0.341188\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "par_time = time.time()\n",
    "\n",
    "par = df.parallel_apply(l1_norm, axis=1)\n",
    "\n",
    "par_time = time.time() - par_time\n",
    "print(par_time)\n",
    "par.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c383692-d647-4500-b6fa-844e6d117b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct!\n",
      "Your score is now 5\n"
     ]
    }
   ],
   "source": [
    "sol.q5_check(seq,seq_time,par,par_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e0c442-ff58-4c6a-89e7-fdc95f3a48ba",
   "metadata": {},
   "source": [
    "Now hopefully you can appreciate the \n",
    "reduction in time offered by the parallel processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16f74ba-54e8-4e88-a1c6-2c8e55bf0db5",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "This is a bonus task for your learning. It is not necessary that you solve this, but give it a try\n",
    "\n",
    "In this step what you have to is to use what you have learned and add a column `ORD_Color` to the dataset containing the ordinal encoding of the `'Color'` column, you must use parallel processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267005b7-4a11-43eb-86bc-54376fba4eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "746cf4c82fbb479a8755b998dadbb8d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=312500), Label(value='0 / 312500')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "def ORD_Color(x):\n",
    "    return np.random.choice(['Red','Blue','Green'])\n",
    "\n",
    "df['ORD_Color']=df.parallel_apply(ORD_Color, axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d70c6c-4f53-4d4e-8a27-c67f64ec2de9",
   "metadata": {},
   "source": [
    "<font color = \"Red\"><B><h1>Mult Threading and Multi Processing</h1></B></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffff5841-5da3-4034-9c5f-a3db3098e5b0",
   "metadata": {},
   "source": [
    "Before moving further, run the cell below to have an basic idea of Threading in Python.<br>\n",
    "Here, in this code we have made three separate threads - \n",
    "1. The main Thread\n",
    "2. t1 thread\n",
    "3. t2 thread\n",
    "\n",
    "t1 thread is responsible for printing 'Hello' while the t2 thread is responsible for 'Hi' and the main thread is the main thread, here in this case it is reponsible for printing 'Bye'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10711f1b-c2e7-4a58-b715-3841e152c494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "Hi\n",
      "Hello\n",
      "Hi\n",
      "Hello\n",
      "Hi\n",
      "Hello\n",
      "Hi\n",
      "Hello\n",
      "Hi\n",
      "Bye\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nIf you want to explore more: We have a small piece of code for your help:\\nJust uncomment it and run it in a different cell.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The first imports the sleep function from time module- it is used wait at the line for a given time.\n",
    "## The second line is to import the inbuilt 'Threading' module of Python.\n",
    "from time import sleep \n",
    "from multiprocessing import Process   \n",
    "from threading import *\n",
    "class demo():\n",
    "\n",
    "    class Hello(Thread):\n",
    "          def run(self):  \n",
    "            for i in range(5):\n",
    "              print(\"Hello\")\n",
    "              sleep(1)  # waits for 1 milli seconds at this line.\n",
    "\n",
    "    class Hi(Thread):\n",
    "          def run(self):\n",
    "            for i in range(5):\n",
    "              print(\"Hi\")\n",
    "              sleep(1)\n",
    "\n",
    "    t1 = Process(target=Hello().run)\n",
    "    t2 = Process(target=Hi().run)\n",
    "\n",
    "    t1.start()   # calls the run function of t1 class (Hello class). \n",
    "    sleep(0.2)\n",
    "    t2.start()   # calls the run function of the t2 class (Hi class).\n",
    "\n",
    "    '''\n",
    "    The below lines are helpful in executing the t1 thread and t2 thread first before the \n",
    "    execution of Main Thread. To understand more clearly, just comment out the two lines \n",
    "    and then run the cell to see the difference.\n",
    "    '''\n",
    "    t1.join()\n",
    "    t2.join()\n",
    "\n",
    "    print(\"Bye\")\n",
    "\n",
    "demo()\n",
    "\n",
    "'''\n",
    "If you want to explore more: We have a small piece of code for your help:\n",
    "Just uncomment it and run it in a different cell.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e30cd79f-7061-47c1-99b1-9b1284b83e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello bob\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nBonus Task:\\nWith the help of multiprocessing module of python, try to initialise the 't1' and \\n't2' as Process() [ as did in commented code ], and so try to improve the functionality of this code.\\nWatch this video to get more idea -\\n'https://www.youtube.com/watch?v=fKl2JW_qrso'\\n\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#: Hope you remember the Process function from the slides !\n",
    "\n",
    "from multiprocessing import Process   \n",
    "\n",
    "def f(name):\n",
    "    print('hello', name)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    p = Process(target=f, args=('bob',))\n",
    "    p.start()\n",
    "    p.join()\n",
    "\n",
    "'''\n",
    "Bonus Task:\n",
    "With the help of multiprocessing module of python, try to initialise the 't1' and \n",
    "'t2' as Process() [ as did in commented code ], and so try to improve the functionality of this code.\n",
    "Watch this video to get more idea -\n",
    "'https://www.youtube.com/watch?v=fKl2JW_qrso'\n",
    "\n",
    "'''\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a0ac76-c71a-46bc-8068-c3169fc5c005",
   "metadata": {},
   "source": [
    "# In this task you have to literally do nothing !\n",
    "# You just have to tweak the range of the iteration(the for loop) to figure out the relationship between the overall time taken to perform the task and the computation complexity of the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fd28b30-a09b-47b1-a94d-c8585951c11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pool time =  0.34157800674438477\n",
      "Serial Processing time =  1.2737984657287598\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Run the below code to get an intution of what is happenening, here.\n",
    "'''\n",
    "\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "\n",
    "\n",
    "def square_add(x):\n",
    "      sum = 0\n",
    "      for j in range(1000):\n",
    "        sum += j*j\n",
    "      return sum\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "          toc = time.time()\n",
    "          p = Pool()\n",
    "          result = p.map(square_add, range(10000))\n",
    "          p.close()\n",
    "          p.join()\n",
    "          tic = time.time()\n",
    "          print(\"Pool time = \", tic-toc)\n",
    "\n",
    "          toc = time.time()\n",
    "          result = []\n",
    "\n",
    "          for i in range(10000):\n",
    "                  result.append(square_add(i))\n",
    "          tic = time.time()\n",
    "          print(\"Serial Processing time = \", tic-toc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24539ad-adc6-4783-9544-10eb883f4922",
   "metadata": {},
   "source": [
    "# The Task below is designed to get your hands on the type of Shared Memory among processes as discussed in the slides.<br>\n",
    "Read the INSTRUCTIONS carefully to get an idea of your task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e71609d-b6fb-4449-9226-791af9a68a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-35:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ug2019/eee/19085089/.conda/envs/multi/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ug2019/eee/19085089/.conda/envs/multi/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_31248/3848516475.py\", line 30, in getSquares\n",
      "    for index, num in enumerate(numbers):\n",
      "TypeError: enumerate() takes 0 positional arguments but 1 was given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Task7 at 0x7f7c7a892278>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "INSTRUCTIONS:\n",
    "1. FIRST of all COMMENT the four line of codes (as instructed).\n",
    "2. Once done that run the cell to see the output. Now, UNCOMMENT the said four lines.\n",
    "3. Now, run the cell and see the output.\n",
    "4. You might have noticed the difference in output-in one case you have blank array while you got filled array in other case.\n",
    "5. The reason behind this was - those four lines just make the memory sharing possible between the two processes.\n",
    "6. One in he main process (under the if __name__ == \"__main__: command) and the other is in the 'getSquare' function.\n",
    "7. This is called 'queue pipe Multiprocessing'.\n",
    "\n",
    "YOUR TASK:\n",
    "1. Create a function named 'getNumSquare'. In this function you will take one argument 'num'\n",
    "2. This 'num' is a shared Memory of type 'value' and is to be declared as 'double'.\n",
    "3. You just have to assign a real number to the 'num' variable inside the function and get it printed \n",
    "  in the 'if statement' (if __name_ == \"__main__\")\n",
    "4. We have added multiprocessing.active_children() for you in the bottom of code which prints number of active workers.\n",
    "5. You job is to just add 1 line of code to get the numbers of CPU in the system.(There is a inbulit function for this).\n",
    "\n",
    "BONUS TASK:\n",
    "1. Repeat the same task for a Queue type shared Memory in a new cell.\n",
    "2. You have to use queue.put()- to put the numbers in a variable named 'queue' of type Queue.\n",
    "3. Also queue.get() - to fetch the data in the queue.\n",
    "''' \n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "class Task7():\n",
    "    \n",
    "    def getSquares(numbers, result):    \n",
    "          for index, num in enumerate(numbers):\n",
    "                result[index] = num*num\n",
    "          eval = result\n",
    "          return eval\n",
    "\n",
    "    if __name__ == \"__main__\":\n",
    "          numbers = [2,3,5]\n",
    "          result = []\n",
    "\n",
    "          ###  COMMENT FOUR LINES BELOW  ####\n",
    "          result = multiprocessing.Array('i', 3)\n",
    "          p = multiprocessing.Process(target=getSquares, args=(numbers, result))\n",
    "\n",
    "          p.start()\n",
    "          p.join()\n",
    "\n",
    "          #### THE FOUR LINES TO BE COMMENTED   #######\n",
    "\n",
    "          print(multiprocessing.active_children())\n",
    "          print(result[:])\n",
    "    \n",
    "Task7()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921f3040-14c3-4f1a-87c9-e0bd689be06c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
