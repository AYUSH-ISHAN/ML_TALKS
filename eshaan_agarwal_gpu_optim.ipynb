{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0182193a-0156-43f7-96cb-0d6012e4575a",
   "metadata": {
    "tags": []
   },
   "source": [
    "<B><h1><font color = \"green\" size = '20'>HANDOUT ASSIGNMENTS : </font></h1></B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d96150c-19aa-4207-a097-56ab1dc2def0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete\n"
     ]
    }
   ],
   "source": [
    "# YOU HAVE TO RUN THIS CODE EVERYTIME YOU RESTART THE KERNEL\n",
    "from checker.assignment1 import Solution\n",
    "#Enter your name in quotes with underscore for space below\n",
    "sol = Solution('eshaan_agarwal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d56c48-ff63-4839-b4fb-4370532f1515",
   "metadata": {},
   "source": [
    "<h1><B><font color = 'red'>GPU OPTIMISATION</font><B></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d9e6a5-f38e-4377-8cbd-d3f998813c2f",
   "metadata": {},
   "source": [
    "# In the below question, we want you to make some changes, so that m1, m2, product are all on the GPU \n",
    "\n",
    "# You can run the cell containing checker code to see whether you succeeded or not.\n",
    "Note : You may have to restart the kernel everytime you change the GPU, the kernel restart option is available under the kernel menu in top left.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d092a609-f262-4c01-bca8-0476256ec5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n",
      "/device:GPU:1\n",
      "/device:GPU:1\n",
      "/device:GPU:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-19 17:55:40.461054: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:04:00.0\n",
      "2021-08-19 17:55:40.463328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:05:00.0\n",
      "2021-08-19 17:55:40.465574: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 2 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:08:00.0\n",
      "2021-08-19 17:55:40.467422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 3 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:09:00.0\n",
      "2021-08-19 17:55:40.469554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 4 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:89:00.0\n",
      "2021-08-19 17:55:40.469638: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-08-19 17:55:40.469670: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-08-19 17:55:40.469697: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-08-19 17:55:40.469723: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-08-19 17:55:40.469748: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-08-19 17:55:40.469774: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-08-19 17:55:40.469801: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-08-19 17:55:40.488525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1, 2, 3, 4\n",
      "2021-08-19 17:55:40.488630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-08-19 17:55:40.488647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 2 3 4 \n",
      "2021-08-19 17:55:40.488658: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N Y Y Y N \n",
      "2021-08-19 17:55:40.488666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   Y N Y Y N \n",
      "2021-08-19 17:55:40.488674: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 2:   Y Y N Y N \n",
      "2021-08-19 17:55:40.488682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 3:   Y Y Y N N \n",
      "2021-08-19 17:55:40.488698: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 4:   N N N N N \n",
      "2021-08-19 17:55:40.499602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10489 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1)\n",
      "2021-08-19 17:55:40.501449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10489 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:05:00.0, compute capability: 6.1)\n",
      "2021-08-19 17:55:40.503261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10489 MB memory) -> physical GPU (device: 2, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:08:00.0, compute capability: 6.1)\n",
      "2021-08-19 17:55:40.504856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 10342 MB memory) -> physical GPU (device: 3, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:09:00.0, compute capability: 6.1)\n",
      "2021-08-19 17:55:40.506679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:4 with 10489 MB memory) -> physical GPU (device: 4, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:89:00.0, compute capability: 6.1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "## CHANGE BELOW CODE\n",
    "\n",
    "with tf.device('/gpu:1'):\n",
    "    m1 = tf.constant([[3., 5.]])\n",
    "    m2 = tf.constant([[2.],[4.]])\n",
    "\n",
    "    product = tf.matmul(m1, m2)    # A matrix multiplication op node\n",
    "\n",
    "\n",
    "## CHANGE ABOVE CODE\n",
    "sess = tf.Session()\n",
    "\n",
    "print(product.device)\n",
    "print(m1.device)\n",
    "print(m2.device)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1852fdae-15f2-4ddb-b59e-16028fbd2d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct!\n",
      "Your score is now 1\n"
     ]
    }
   ],
   "source": [
    "sol.q1_check(m1,m2,product) #RUN THIS CELL WITHOUT CHANGE TO SEE YOUR SCORE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c86993-11a8-4fd9-8af7-fc97a79251f4",
   "metadata": {},
   "source": [
    "# In the next task, we are providing you a boiler plate code based on Model Parallelism. \n",
    "You have to complete the following task in your code:\n",
    "We have already initialised two matrix of dimension 2X2, a and b, with random values.\n",
    "Now you have to implement this three steps.\n",
    "\n",
    "\n",
    "1.   Use gpu with id '0' to perform matrix multiplication and append it in  the list 'c'.\n",
    "2.  Use gpu with id '1' to perform atrix multiplication of 'a' and 'b'. And append it in list 'c'.\n",
    "3.  Add all the matrix which you appended in list 'c' above and store result in sum. You have to use cpu with id '0' for this step.\n",
    "\n",
    "In case the gpus are not available, you can try in other gpus (id 0-4), just make sure both gpus are not the same.\n",
    "\n",
    "### Reminder: you may have to restart kernel everytime you change gpus/cpus in code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba44adb5-0007-4122-ba02-23fb927a5693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_26792/1476125978.py:7: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_26792/1476125978.py:32: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-19 18:01:18.707359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:04:00.0\n",
      "2021-08-19 18:01:18.709392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:05:00.0\n",
      "2021-08-19 18:01:18.711335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 2 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:08:00.0\n",
      "2021-08-19 18:01:18.712984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 3 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:09:00.0\n",
      "2021-08-19 18:01:18.714877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 4 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:89:00.0\n",
      "2021-08-19 18:01:18.714952: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-08-19 18:01:18.714997: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-08-19 18:01:18.715020: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-08-19 18:01:18.715043: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-08-19 18:01:18.715067: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-08-19 18:01:18.715089: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-08-19 18:01:18.715112: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-08-19 18:01:18.732418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1, 2, 3, 4\n",
      "2021-08-19 18:01:18.732525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-08-19 18:01:18.732542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 2 3 4 \n",
      "2021-08-19 18:01:18.732551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N Y Y Y N \n",
      "2021-08-19 18:01:18.732560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   Y N Y Y N \n",
      "2021-08-19 18:01:18.732567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 2:   Y Y N Y N \n",
      "2021-08-19 18:01:18.732575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 3:   Y Y Y N N \n",
      "2021-08-19 18:01:18.732582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 4:   N N N N N \n",
      "2021-08-19 18:01:18.743070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10489 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1)\n",
      "2021-08-19 18:01:18.744916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10489 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:05:00.0, compute capability: 6.1)\n",
      "2021-08-19 18:01:18.746701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10489 MB memory) -> physical GPU (device: 2, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:08:00.0, compute capability: 6.1)\n",
      "2021-08-19 18:01:18.748246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 10342 MB memory) -> physical GPU (device: 3, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:09:00.0, compute capability: 6.1)\n",
      "2021-08-19 18:01:18.750061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:4 with 10489 MB memory) -> physical GPU (device: 4, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:89:00.0, compute capability: 6.1)\n",
      "2021-08-19 18:01:19.654016: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.19135648 -0.16396901]\n",
      " [-0.18112698  0.07006835]]\n",
      "/device:GPU:0\n",
      "/device:GPU:1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# list 'c' in which we will append our list\n",
    "c = []\n",
    "# random initialisation of two matrices 'a' and 'b'.\n",
    "a = tf.get_variable(f\"a\", [2, 2], initializer=tf.random_uniform_initializer(-1, 1))\n",
    "b = tf.get_variable(f\"b\", [2, 2], initializer=tf.random_uniform_initializer(-1, 1))\n",
    "\n",
    "##### START CODE HERE  #######\n",
    "\n",
    "'''\n",
    "HINTS :\n",
    "You have to initialise three devices as asked above (gpu-0, gpu-1, cpu-0).\n",
    "After initialisation perform the task in each f those initialisation.\n",
    "For matrix multiplication, look at above task.\n",
    "While for addition part - Find Yourself.\n",
    "'''\n",
    "for i, d in enumerate(['/gpu:0','/gpu:1']):\n",
    "    with tf.device(d):\n",
    "        c.append(tf.matmul(a,b))\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    sum=tf.add_n(c)\n",
    "    \n",
    "#### YOU CODE ENDS HERE   ######\n",
    "\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "print(sess.run(sum))\n",
    "print(c[0].device)\n",
    "print(c[1].device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8424057e-ffb9-4acf-b058-0d7f318e0857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct!\n",
      "Your score is now 2\n"
     ]
    }
   ],
   "source": [
    "sol.q2_check(c)  #RUn THIS CELL TO SEE IF YOU ARE CORRECT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc303a6-1b21-46d8-bd13-7e56bd19121b",
   "metadata": {},
   "source": [
    "# Now in this task you will be dealing with Data Parallelism\n",
    "We have declared two tensors a and b, you just have to complete the code so that the matrix multiplication is done in two GPUs with different set of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "982ae848-3ef5-4a06-b46a-9e2ce6d03d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_30525/346825096.py:6: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "<tf.Variable 'a:0' shape=(2, 4, 3) dtype=float32_ref>\n",
      "WARNING:tensorflow:From /tmp/ipykernel_30525/346825096.py:17: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-19 19:40:46.810033: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-08-19 19:40:46.841232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:04:00.0\n",
      "2021-08-19 19:40:46.842949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:05:00.0\n",
      "2021-08-19 19:40:46.844656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 2 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:08:00.0\n",
      "2021-08-19 19:40:46.846162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 3 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:09:00.0\n",
      "2021-08-19 19:40:46.847917: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 4 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:89:00.0\n",
      "2021-08-19 19:40:46.848446: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-08-19 19:40:46.850924: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-08-19 19:40:46.853381: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-08-19 19:40:46.853980: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-08-19 19:40:46.857043: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-08-19 19:40:46.859416: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-08-19 19:40:46.866178: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-08-19 19:40:46.882659: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1, 2, 3, 4\n",
      "2021-08-19 19:40:46.883560: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2021-08-19 19:40:46.895543: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1700085000 Hz\n",
      "2021-08-19 19:40:46.898218: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d36af52870 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-08-19 19:40:46.898254: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_30525/346825096.py:19: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-19 19:40:47.685331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:04:00.0\n",
      "2021-08-19 19:40:47.686883: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:05:00.0\n",
      "2021-08-19 19:40:47.688387: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 2 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:08:00.0\n",
      "2021-08-19 19:40:47.689885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 3 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:09:00.0\n",
      "2021-08-19 19:40:47.693785: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 4 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:89:00.0\n",
      "2021-08-19 19:40:47.693868: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-08-19 19:40:47.693897: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-08-19 19:40:47.693920: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-08-19 19:40:47.693941: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-08-19 19:40:47.693963: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-08-19 19:40:47.693983: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-08-19 19:40:47.694005: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-08-19 19:40:47.708445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1, 2, 3, 4\n",
      "2021-08-19 19:40:47.708511: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-08-19 19:40:47.718990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-08-19 19:40:47.719023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 2 3 4 \n",
      "2021-08-19 19:40:47.719043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N Y Y Y N \n",
      "2021-08-19 19:40:47.719052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   Y N Y Y N \n",
      "2021-08-19 19:40:47.719061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 2:   Y Y N Y N \n",
      "2021-08-19 19:40:47.719071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 3:   Y Y Y N N \n",
      "2021-08-19 19:40:47.719079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 4:   N N N N N \n",
      "2021-08-19 19:40:47.729515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10178 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1)\n",
      "2021-08-19 19:40:47.735723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10178 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:05:00.0, compute capability: 6.1)\n",
      "2021-08-19 19:40:47.739010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10359 MB memory) -> physical GPU (device: 2, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:08:00.0, compute capability: 6.1)\n",
      "2021-08-19 19:40:47.742888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 10211 MB memory) -> physical GPU (device: 3, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:09:00.0, compute capability: 6.1)\n",
      "2021-08-19 19:40:47.746179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:4 with 10359 MB memory) -> physical GPU (device: 4, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:89:00.0, compute capability: 6.1)\n",
      "2021-08-19 19:40:47.750759: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d36ca52900 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2021-08-19 19:40:47.750800: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2021-08-19 19:40:47.750815: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2021-08-19 19:40:47.750827: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2021-08-19 19:40:47.750840: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2021-08-19 19:40:47.750851: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (4): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2021-08-19 19:40:48.580122: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.129454    1.2050676 ]\n",
      " [ 0.8994162  -1.3503548 ]\n",
      " [-0.7103846   0.54095376]\n",
      " [-1.0096722  -0.03303215]]\n",
      "/device:GPU:2\n",
      "/device:GPU:3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "c = []\n",
    "a = tf.get_variable(f\"a\", [2, 4, 3], initializer=tf.random_uniform_initializer(-1, 1))  # [2,2,3]\n",
    "b = tf.get_variable(f\"b\", [2, 3, 2], initializer=tf.random_uniform_initializer(-1, 1))\n",
    "print(a)\n",
    "# Multiple towers\n",
    "for i, d in enumerate(['/gpu:2','/gpu:3']):   # Complete Code.\n",
    "    with tf.device(d):                        #Complete Code\n",
    "        c.append(tf.matmul(a[i], b[i]))# Tower i is responsible for batch data i.\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    sum = tf.add_n(c)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "print(sess.run(sum))   \n",
    "print(c[0].device)\n",
    "print(c[1].device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "498e9a30-bc17-4df2-a626-c5b35f73a16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct!\n",
      "Your score is now 5\n"
     ]
    }
   ],
   "source": [
    "sol.q3_check(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98483dbb-9c12-4c5c-8af1-e0449484f702",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "# <font color = \"red\">PANDARALLEL</font>\n",
    "In this part we practice with the pandarallel library that allows parallel processing of DataFrames. \n",
    "\n",
    "#### Note: pandarallel can speed up computation using the physical cores present, hyperthreading does not increase speed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e147c359-188a-47ca-8ca9-ce4712075566",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Run this code before attempting the excerise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2513006e-92ad-4296-a2c6-dc706ce46051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XCoordinate</th>\n",
       "      <th>YCoordinate</th>\n",
       "      <th>Color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.988137</td>\n",
       "      <td>0.554130</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.202205</td>\n",
       "      <td>0.636993</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.177485</td>\n",
       "      <td>-0.964328</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.266259</td>\n",
       "      <td>0.401165</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.307670</td>\n",
       "      <td>-0.182452</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   XCoordinate  YCoordinate  Color\n",
       "0    -0.988137     0.554130   Blue\n",
       "1    -0.202205     0.636993  Green\n",
       "2    -0.177485    -0.964328  Green\n",
       "3    -1.266259     0.401165    Red\n",
       "4     1.307670    -0.182452   Blue"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "\n",
    "tqdm.pandas()\n",
    "size = int(5e6)\n",
    "\n",
    "# Synthetic dataset of random points\n",
    "df = pd.DataFrame({\n",
    "    'XCoordinate': np.random.randn(size),\n",
    "    'YCoordinate': np.random.randn(size),\n",
    "    'Color': np.random.choice(['Red','Blue','Green'],size)\n",
    "})\n",
    "# Preview of dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b57ba2e-d44e-451b-8668-7132c4a11c94",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "For starters you have to first import the `pandarallel` class from the pandarallel module and run the `initialize()` method of the class. You can pass `progress_bar=True` to `initialize()` if you want to see progress bars.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0baac3c1-f93e-406b-91e3-c4c528706247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 16 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "870559f6-a74a-4026-b17a-eeac22697bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct!\n",
      "Your score is now 3\n"
     ]
    }
   ],
   "source": [
    "sol.q4_check(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40b72ce-52a4-4f84-8675-871719cde59f",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "We have defined the function `l1_norm` here that takes a row in the `DataFrame` as argument and returns the L1 Norm of the point, i.e sum of absolute values of the coordinates. Run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6ce0f37-b10a-44fc-bda2-1cfdd49740ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_norm(row):\n",
    "      return row.XCoordinate + row.YCoordinate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be387d1b-eae8-452c-b5e7-c297f4754c12",
   "metadata": {},
   "source": [
    "Next we will apply the function to each row by calling the `progress_apply()` method on the `DataFrame`. This may take a minute or two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf41df2e-a514-48ef-aadd-d1ab678da9e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6319640866f94e0e9c39d30ef7a0d34b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169.09344124794006\n",
      "CPU times: user 2min 47s, sys: 3.39 s, total: 2min 50s\n",
      "Wall time: 2min 49s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XCoordinate</th>\n",
       "      <th>YCoordinate</th>\n",
       "      <th>Color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.192522</td>\n",
       "      <td>-1.349822</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.212885</td>\n",
       "      <td>-0.030272</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.051308</td>\n",
       "      <td>1.640772</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.997334</td>\n",
       "      <td>1.784383</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.864108</td>\n",
       "      <td>0.073674</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   XCoordinate  YCoordinate  Color\n",
       "0    -0.192522    -1.349822  Green\n",
       "1    -0.212885    -0.030272   Blue\n",
       "2     0.051308     1.640772   Blue\n",
       "3     0.997334     1.784383    Red\n",
       "4     0.864108     0.073674   Blue"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "seq_time = time.time()\n",
    "\n",
    "seq = df.progress_apply(l1_norm,axis=1)\n",
    "\n",
    "seq_time = time.time() - seq_time\n",
    "print(seq_time)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7c402b-ed7d-4b26-a644-0b62bbdc9b2d",
   "metadata": {},
   "source": [
    "Now your task is to process each row with the same function but now \n",
    "\n",
    "using parallel processing provided with the help of `pandarallel` . You can compre the time with the previous execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a43b6405-8ccc-4488-b699-c9f5f8a333d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01c4d67f686746db8cd8cf6bd166e646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=312500), Label(value='0 / 312500')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.153860330581665\n",
      "CPU times: user 2.95 s, sys: 962 ms, total: 3.91 s\n",
      "Wall time: 13.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0   -1.542345\n",
       "1   -0.243157\n",
       "2    1.692080\n",
       "3    2.781717\n",
       "4    0.937783\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "par_time = time.time()\n",
    "\n",
    "par =df.parallel_apply(l1_norm,axis=1)\n",
    "\n",
    "par_time = time.time() - par_time\n",
    "print(par_time)\n",
    "par.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c383692-d647-4500-b6fa-844e6d117b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct!\n",
      "Your score is now 4\n"
     ]
    }
   ],
   "source": [
    "sol.q5_check(seq,seq_time,par,par_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e0c442-ff58-4c6a-89e7-fdc95f3a48ba",
   "metadata": {},
   "source": [
    "Now hopefully you can appreciate the \n",
    "reduction in time offered by the parallel processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16f74ba-54e8-4e88-a1c6-2c8e55bf0db5",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "This is a bonus task for your learning. It is not necessary that you solve this, but give it a try\n",
    "\n",
    "In this step what you have to is to use what you have learned and add a column `ORD_Color` to the dataset containing the ordinal encoding of the `'Color'` column, you must use parallel processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "267005b7-4a11-43eb-86bc-54376fba4eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fe756b3c0c544a285da52115f242b26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=312500), Label(value='0 / 312500')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "def ordinal_mapper(row):\n",
    "    ordinal_map = {\"Red\":1, \"Blue\":2, \"Green\":3}\n",
    "    if row.Color== \"Red\":\n",
    "        return 1\n",
    "    elif row.Color==\"Blue\":\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "df[\"ORD_Color\"] = df.parallel_apply(ordinal_mapper,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61efc4ec-e3a1-4115-860d-4c5f66a8dd2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XCoordinate</th>\n",
       "      <th>YCoordinate</th>\n",
       "      <th>Color</th>\n",
       "      <th>ORD_Color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.988137</td>\n",
       "      <td>0.554130</td>\n",
       "      <td>Blue</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.202205</td>\n",
       "      <td>0.636993</td>\n",
       "      <td>Green</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.177485</td>\n",
       "      <td>-0.964328</td>\n",
       "      <td>Green</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.266259</td>\n",
       "      <td>0.401165</td>\n",
       "      <td>Red</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.307670</td>\n",
       "      <td>-0.182452</td>\n",
       "      <td>Blue</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999995</th>\n",
       "      <td>2.434648</td>\n",
       "      <td>-1.294677</td>\n",
       "      <td>Red</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999996</th>\n",
       "      <td>1.052484</td>\n",
       "      <td>-0.961209</td>\n",
       "      <td>Green</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999997</th>\n",
       "      <td>0.170079</td>\n",
       "      <td>-0.264612</td>\n",
       "      <td>Green</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999998</th>\n",
       "      <td>0.101100</td>\n",
       "      <td>0.295757</td>\n",
       "      <td>Green</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999999</th>\n",
       "      <td>-0.666620</td>\n",
       "      <td>-0.439484</td>\n",
       "      <td>Blue</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         XCoordinate  YCoordinate  Color  ORD_Color\n",
       "0          -0.988137     0.554130   Blue          2\n",
       "1          -0.202205     0.636993  Green          3\n",
       "2          -0.177485    -0.964328  Green          3\n",
       "3          -1.266259     0.401165    Red          1\n",
       "4           1.307670    -0.182452   Blue          2\n",
       "...              ...          ...    ...        ...\n",
       "4999995     2.434648    -1.294677    Red          1\n",
       "4999996     1.052484    -0.961209  Green          3\n",
       "4999997     0.170079    -0.264612  Green          3\n",
       "4999998     0.101100     0.295757  Green          3\n",
       "4999999    -0.666620    -0.439484   Blue          2\n",
       "\n",
       "[5000000 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d70c6c-4f53-4d4e-8a27-c67f64ec2de9",
   "metadata": {},
   "source": [
    "<font color = \"Red\"><B><h1>Mult Threading and Multi Processing</h1></B></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffff5841-5da3-4034-9c5f-a3db3098e5b0",
   "metadata": {},
   "source": [
    "Before moving further, run the cell below to have an basic idea of Threading in Python.<br>\n",
    "Here, in this code we have made three separate threads - \n",
    "1. The main Thread\n",
    "2. t1 thread\n",
    "3. t2 thread\n",
    "\n",
    "t1 thread is responsible for printing 'Hello' while the t2 thread is responsible for 'Hi' and the main thread is the main thread, here in this case it is reponsible for printing 'Bye'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a090246-e1d9-45fd-bea7-cbbe9d934eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "Hi\n",
      "Hello\n",
      "Hi\n",
      "Hello\n",
      "Hi\n",
      "Hello\n",
      "Hi\n",
      "Hello\n",
      "Hi\n",
      "Bye\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nBonus Task:\\nWith the help of multiprocessing module of python, try to initialise the 't1' and \\n't2' as Process() [ as did in commented code ], and so try to improve the functionality of this code.\\nWatch this video to get more idea -\\n'https://www.youtube.com/watch?v=fKl2JW_qrso'\\n\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The first imports the sleep function from time module- it is used wait at the line for a given time.\n",
    "## The second line is to import the inbuilt 'Threading' module of Python.\n",
    "from time import sleep \n",
    "from threading import *\n",
    "from multiprocessing import Process   \n",
    "class demo():\n",
    "\n",
    "    class Hello(Thread):\n",
    "          def run(self):  \n",
    "            for i in range(5):\n",
    "              print(\"Hello\")\n",
    "              sleep(1)  # waits for 1 milli seconds at this line.\n",
    "\n",
    "    class Hi(Thread):\n",
    "          def run(self):\n",
    "            for i in range(5):\n",
    "              print(\"Hi\")\n",
    "              sleep(1)\n",
    "\n",
    "    t1 = Hello()\n",
    "    t2= Hi()\n",
    "\n",
    "    t1.start()   # calls the run function of t1 class (Hello class). \n",
    "    sleep(0.2)\n",
    "    t2.start()   # calls the run function of the t2 class (Hi class).\n",
    "\n",
    "    '''\n",
    "    The below lines are helpful in executing the t1 thread and t2 thread first before the \n",
    "    execution of Main Thread. To understand more clearly, just comment out the two lines \n",
    "    and then run the cell to see the difference.\n",
    "    '''\n",
    "    t1.join()\n",
    "    t2.join()\n",
    "\n",
    "    print(\"Bye\")\n",
    "\n",
    "demo()\n",
    "\n",
    "'''\n",
    "If you want to explore more: We have a small piece of code for your help:\n",
    "Just uncomment it and run it in a different cell.\n",
    "'''\n",
    "#: Hope you remember the Process function from the slides !\n",
    "\n",
    "# from multiprocessing import Process   \n",
    "\n",
    "# def f(name):\n",
    "#     print('hello', name)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     p = Process(target=f, args=('bob',))\n",
    "#     p.start()\n",
    "#     p.join()\n",
    "\n",
    "'''\n",
    "Bonus Task:\n",
    "With the help of multiprocessing module of python, try to initialise the 't1' and \n",
    "'t2' as Process() [ as did in commented code ], and so try to improve the functionality of this code.\n",
    "Watch this video to get more idea -\n",
    "'https://www.youtube.com/watch?v=fKl2JW_qrso'\n",
    "\n",
    "'''\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40b453b8-9ab7-4363-89d6-2878203922f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "Hi\n",
      "Hello\n",
      "Hi\n",
      "Hello\n",
      "Hi\n",
      "Hello\n",
      "Hi\n",
      "Hello\n",
      "Hi\n",
      "Bye\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nBonus Task:\\nWith the help of multiprocessing module of python, try to initialise the 't1' and \\n't2' as Process() [ as did in commented code ], and so try to improve the functionality of this code.\\nWatch this video to get more idea -\\n'https://www.youtube.com/watch?v=fKl2JW_qrso'\\n\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The first imports the sleep function from time module- it is used wait at the line for a given time.\n",
    "## The second line is to import the inbuilt 'Threading' module of Python.\n",
    "from time import sleep \n",
    "from threading import *\n",
    "from multiprocessing import Process   \n",
    "class demo():\n",
    "\n",
    "    class Hello(Thread):\n",
    "          def run(self):  \n",
    "            for i in range(5):\n",
    "              print(\"Hello\")\n",
    "              sleep(1)  # waits for 1 milli seconds at this line.\n",
    "\n",
    "    class Hi(Thread):\n",
    "          def run(self):\n",
    "            for i in range(5):\n",
    "              print(\"Hi\")\n",
    "              sleep(1)\n",
    "\n",
    "    hello = Hello()\n",
    "    hi= Hi()\n",
    "    t1=Process(target=hello.run)\n",
    "    t2=Process(target=hi.run)\n",
    "\n",
    "    t1.start()   # calls the run function of t1 class (Hello class). \n",
    "    sleep(0.2)\n",
    "    t2.start()   # calls the run function of the t2 class (Hi class).\n",
    "\n",
    "    '''\n",
    "    The below lines are helpful in executing the t1 thread and t2 thread first before the \n",
    "    execution of Main Thread. To understand more clearly, just comment out the two lines \n",
    "    and then run the cell to see the difference.\n",
    "    '''\n",
    "    t1.join()\n",
    "    t2.join()\n",
    "\n",
    "    print(\"Bye\")\n",
    "\n",
    "demo()\n",
    "#########################BONUS TASK################\n",
    "'''\n",
    "If you want to explore more: We have a small piece of code for your help:\n",
    "Just uncomment it and run it in a different cell.\n",
    "'''\n",
    "#: Hope you remember the Process function from the slides !\n",
    "\n",
    "# from multiprocessing import Process   \n",
    "\n",
    "# def f(name):\n",
    "#     print('hello', name)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     p = Process(target=f, args=('bob',))\n",
    "#     p.start()\n",
    "#     p.join()\n",
    "\n",
    "'''\n",
    "Bonus Task:\n",
    "With the help of multiprocessing module of python, try to initialise the 't1' and \n",
    "'t2' as Process() [ as did in commented code ], and so try to improve the functionality of this code.\n",
    "Watch this video to get more idea -\n",
    "'https://www.youtube.com/watch?v=fKl2JW_qrso'\n",
    "\n",
    "'''\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4de76fa6-8153-491d-b903-7226044c9bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello bob\n"
     ]
    }
   ],
   "source": [
    "# : Hope you remember the Process function from the slides !\n",
    "\n",
    "from multiprocessing import Process   \n",
    "\n",
    "def f(name):\n",
    "    print('hello', name)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    p = Process(target=f, args=('bob',))\n",
    "    p.start()\n",
    "    p.join()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a0ac76-c71a-46bc-8068-c3169fc5c005",
   "metadata": {},
   "source": [
    "# In this task you have to literally do nothing !\n",
    "# You just have to tweak the range of the iteration(the for loop) to figure out the relationship between the overall time taken to perform the task and the computation complexity of the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd28b30-a09b-47b1-a94d-c8585951c11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pool time =  0.18389487266540527\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Run the below code to get an intution of what is happenening, here.\n",
    "'''\n",
    "\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "\n",
    "\n",
    "def square_add(x):\n",
    "      sum = 0\n",
    "      for j in range(1000):\n",
    "        sum += j*j\n",
    "      return sum\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "          toc = time.time()\n",
    "          p = Pool()\n",
    "          result = p.map(square_add, range(10000))\n",
    "          p.close()\n",
    "          p.join()\n",
    "          tic = time.time()\n",
    "          print(\"Pool time = \", tic-toc)\n",
    "\n",
    "          toc = time.time()\n",
    "          result = []\n",
    "\n",
    "          for i in range(1000000):\n",
    "                  result.append(square_add(i))\n",
    "          tic = time.time()\n",
    "          print(\"Serial Processing time = \", tic-toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899bb92a-5302-4066-a299-e04f765b30d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "for 1000 - Pool time =  0.8130717277526855\n",
    "           Serial Processing time =  0.12732386589050293\n",
    "for 100000 - Pool time =  0.18219923973083496\n",
    "             Serial Processing time =  12.963986158370972           \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24539ad-adc6-4783-9544-10eb883f4922",
   "metadata": {},
   "source": [
    "# The Task below is designed to get your hands on the type of Shared Memory among processes as discussed in the slides.<br>\n",
    "Read the INSTRUCTIONS carefully to get an idea of your task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e71609d-b6fb-4449-9226-791af9a68a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "16\n",
      "[4, 9, 25]\n",
      "0.8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Task7 at 0x7f95b04eb9b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "INSTRUCTIONS:\n",
    "1. FIRST of all COMMENT the four line of codes (as instructed).\n",
    "2. Once done that run the cell to see the output. Now, UNCOMMENT the said four lines.\n",
    "3. Now, run the cell and see the output.\n",
    "4. You might have noticed the difference in output-in one case you have blank array while you got filled array in other case.\n",
    "5. The reason behind this was - those four lines just make the memory sharing possible between the two processes.\n",
    "6. One in he main process (under the if __name__ == \"__main__: command) and the other is in the 'getSquare' function.\n",
    "7. This is called 'queue pipe Multiprocessing'.\n",
    "\n",
    "YOUR TASK:\n",
    "1. Create a function named 'getNumSquare'. In this function you will take one argument 'num'\n",
    "2. This 'num' is a shared Memory of type 'value' and is to be declared as 'double'.\n",
    "3. You just have to assign a real number to the 'num' variable inside the function and get it printed \n",
    "  in the 'if statement' (if __name_ == \"__main__\")\n",
    "4. We have added multiprocessing.active_children() for you in the bottom of code which prints number of active workers.\n",
    "5. You job is to just add 1 line of code to get the numbers of CPU in the system.(There is a inbulit function for this).\n",
    "\n",
    "BONUS TASK:\n",
    "1. Repeat the same task for a Queue type shared Memory in a new cell.\n",
    "2. You have to use queue.put()- to put the numbers in a variable named 'queue' of type Queue.\n",
    "3. Also queue.get() - to fetch the data in the queue.\n",
    "''' \n",
    "\n",
    "import multiprocessing\n",
    "import random\n",
    "\n",
    "class Task7():\n",
    "    \n",
    "    def getSquares(numbers, result):\n",
    "        for index, num in enumerate(numbers):\n",
    "            result[index] = num*num\n",
    "        eval = result\n",
    "        return eval\n",
    "    \n",
    "    def getNumSquare(num):\n",
    "        num.value= round(random.random(), 1)\n",
    "        return num\n",
    "        \n",
    "    if __name__ == \"__main__\":\n",
    "        numbers = [2,3,5]\n",
    "        result = []\n",
    "        num=0.0\n",
    "\n",
    "          ###  COMMENT FOUR LINES BELOW  ####\n",
    "        result = multiprocessing.Array('i', 3)\n",
    "        num=multiprocessing.Value('d')\n",
    "\n",
    "        p = multiprocessing.Process(target=getSquares, args=(numbers, result))\n",
    "        q= multiprocessing.Process(target=getNumSquare, args=(num,))\n",
    "        p.start()\n",
    "        q.start()\n",
    "        p.join()\n",
    "        q.join()\n",
    "\n",
    "          #### THE FOUR LINES TO BE COMMENTED   #######\n",
    "\n",
    "        print(multiprocessing.active_children())\n",
    "        print(multiprocessing.cpu_count())\n",
    "        print(result[:])\n",
    "        print(num.value)\n",
    "    \n",
    "Task7()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03216032-a591-4797-bba9-0c6057a4c60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Commenting four lines - []\n",
    "                        []\n",
    "                        \n",
    "\n",
    "Uncommenting four lines :[] \n",
    "                        [4, 9, 25]\n",
    "\n",
    "After performing Task - []\n",
    "                        16\n",
    "                        [4, 9, 25]\n",
    "                        0.8\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "921f3040-14c3-4f1a-87c9-e0bd689be06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "16\n",
      "[4, 9, 25]\n",
      "queue [0.6, 0.6, 0.3, 0.6, 0.7, 0.9, 0.9, 0.7, 0.5, 0.5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Task7 at 0x7f2e486076a0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "INSTRUCTIONS:\n",
    "1. FIRST of all COMMENT the four line of codes (as instructed).\n",
    "2. Once done that run the cell to see the output. Now, UNCOMMENT the said four lines.\n",
    "3. Now, run the cell and see the output.\n",
    "4. You might have noticed the difference in output-in one case you have blank array while you got filled array in other case.\n",
    "5. The reason behind this was - those four lines just make the memory sharing possible between the two processes.\n",
    "6. One in he main process (under the if __name__ == \"__main__: command) and the other is in the 'getSquare' function.\n",
    "7. This is called 'queue pipe Multiprocessing'.\n",
    "\n",
    "YOUR TASK:\n",
    "1. Create a function named 'getNumSquare'. In this function you will take one argument 'num'\n",
    "2. This 'num' is a shared Memory of type 'value' and is to be declared as 'double'.\n",
    "3. You just have to assign a real number to the 'num' variable inside the function and get it printed \n",
    "  in the 'if statement' (if __name_ == \"__main__\")\n",
    "4. We have added multiprocessing.active_children() for you in the bottom of code which prints number of active workers.\n",
    "5. You job is to just add 1 line of code to get the numbers of CPU in the system.(There is a inbulit function for this).\n",
    "\n",
    "BONUS TASK:\n",
    "1. Repeat the same task for a Queue type shared Memory in a new cell.\n",
    "2. You have to use queue.put()- to put the numbers in a variable named 'queue' of type Queue.\n",
    "3. Also queue.get() - to fetch the data in the queue.\n",
    "''' \n",
    "# BONUS TASK\n",
    "import multiprocessing\n",
    "import random\n",
    "\n",
    "class Task7():\n",
    "    \n",
    "    def getSquares(numbers, result):\n",
    "        for index, num in enumerate(numbers):\n",
    "            result[index] = num*num\n",
    "        eval = result\n",
    "        return eval\n",
    "    \n",
    "    def getNumSquare(queue):\n",
    "        list=[]\n",
    "        for index in range(10):\n",
    "            \n",
    "            list.append(round(random.random(), 1))\n",
    "        queue.put(list)\n",
    "#         print(queue.get())   \n",
    "        \n",
    "    if __name__ == \"__main__\":\n",
    "        numbers = [2,3,5]\n",
    "        result = []\n",
    "\n",
    "          ###  COMMENT FOUR LINES BELOW  ####\n",
    "        result = multiprocessing.Array('i', 3)\n",
    "        num=multiprocessing.Value('d')\n",
    "        queue=multiprocessing.Queue()\n",
    "        p = multiprocessing.Process(target=getSquares, args=(numbers, result))\n",
    "        r= multiprocessing.Process(target=getNumSquare, args=(queue,))\n",
    "        p.start()\n",
    "        r.start()\n",
    "        p.join()\n",
    "        r.join()\n",
    "\n",
    "          #### THE FOUR LINES TO BE COMMENTED   #######\n",
    "\n",
    "        print(multiprocessing.active_children())\n",
    "        print(multiprocessing.cpu_count())\n",
    "        print(result[:])\n",
    "        print(\"queue\",queue.get())\n",
    "    \n",
    "Task7()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2975ff6-1956-4903-a968-ea07a639681e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c572d070-50b7-441a-9a83-6d0934f582e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
