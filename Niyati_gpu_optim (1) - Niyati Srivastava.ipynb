{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0182193a-0156-43f7-96cb-0d6012e4575a",
   "metadata": {
    "tags": []
   },
   "source": [
    "<B><h1><font color = \"green\" size = '20'>HANDOUT ASSIGNMENTS : </font></h1></B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d96150c-19aa-4207-a097-56ab1dc2def0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete\n"
     ]
    }
   ],
   "source": [
    "# YOU HAVE TO RUN THIS CODE EVERYTIME YOU RESTART THE KERNEL\n",
    "from checker.assignment1 import Solution\n",
    "#Enter your name in quotes with underscore for space below\n",
    "sol = Solution('Niyati_Srivastava')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d56c48-ff63-4839-b4fb-4370532f1515",
   "metadata": {},
   "source": [
    "<h1><B><font color = 'red'>GPU OPTIMISATION</font><B></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d9e6a5-f38e-4377-8cbd-d3f998813c2f",
   "metadata": {},
   "source": [
    "# In the below question, we want you to make some changes, so that m1, m2, product are all on the GPU \n",
    "\n",
    "# You can run the cell containing checker code to see whether you succeeded or not.\n",
    "Note : You may have to restart the kernel everytime you change the GPU, the kernel restart option is available under the kernel menu in top left.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d092a609-f262-4c01-bca8-0476256ec5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n",
      "WARNING:tensorflow:From /tmp/ipykernel_17361/1585956674.py:15: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-20 12:04:21.185051: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-08-20 12:04:21.222014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:04:00.0\n",
      "2021-08-20 12:04:21.223271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:05:00.0\n",
      "2021-08-20 12:04:21.225421: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 2 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:08:00.0\n",
      "2021-08-20 12:04:21.227249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 3 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:09:00.0\n",
      "2021-08-20 12:04:21.229252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 4 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:89:00.0\n",
      "2021-08-20 12:04:21.229927: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-08-20 12:04:21.232990: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-08-20 12:04:21.235774: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-08-20 12:04:21.236526: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-08-20 12:04:21.239925: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-08-20 12:04:21.242620: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-08-20 12:04:21.249990: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-08-20 12:04:21.263966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1, 2, 3, 4\n",
      "2021-08-20 12:04:21.265108: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2021-08-20 12:04:21.278056: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1700085000 Hz\n",
      "2021-08-20 12:04:21.280860: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fdc1a7ebd0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-08-20 12:04:21.280896: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "## CHANGE BELOW CODE\n",
    "\n",
    "with tf.device('/gpu:4'):\n",
    "    m1 = tf.constant([[3., 5.]])\n",
    "    m2 = tf.constant([[2.],[4.]])\n",
    "\n",
    "    product = tf.matmul(m1, m2)    # A matrix multiplication op node\n",
    "\n",
    "\n",
    "## CHANGE ABOVE CODE\n",
    "sess = tf.Session()\n",
    "\n",
    "print(product.device)\n",
    "print(m1.device)\n",
    "print(m2.device)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1852fdae-15f2-4ddb-b59e-16028fbd2d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sol.q1_check(m1,m2,product) #RUN THIS CELL WITHOUT CHANGE TO SEE YOUR SCORE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c86993-11a8-4fd9-8af7-fc97a79251f4",
   "metadata": {},
   "source": [
    "# In the next task, we are providing you a boiler plate code based on Model Parallelism. \n",
    "You have to complete the following task in your code:\n",
    "We have already initialised two matrix of dimension 2X2, a and b, with random values.\n",
    "Now you have to implement this three steps.\n",
    "\n",
    "\n",
    "1.   Use gpu with id '0' to perform matrix multiplication and append it in  the list 'c'.\n",
    "2.  Use gpu with id '1' to perform atrix multiplication of 'a' and 'b'. And append it in list 'c'.\n",
    "3.  Add all the matrix which you appended in list 'c' above and store result in sum. You have to use cpu with id '0' for this step.\n",
    "\n",
    "In case the gpus are not available, you can try in other gpus (id 0-4), just make sure both gpus are not the same.\n",
    "\n",
    "### Reminder: you may have to restart kernel everytime you change gpus/cpus in code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba44adb5-0007-4122-ba02-23fb927a5693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_14330/1379444309.py:8: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_14330/1379444309.py:35: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-20 10:46:50.134708: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-08-20 10:46:50.164503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:04:00.0\n",
      "2021-08-20 10:46:50.166298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:05:00.0\n",
      "2021-08-20 10:46:50.168086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 2 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:08:00.0\n",
      "2021-08-20 10:46:50.169616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 3 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:09:00.0\n",
      "2021-08-20 10:46:50.171380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 4 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:89:00.0\n",
      "2021-08-20 10:46:50.171730: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-08-20 10:46:50.174140: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-08-20 10:46:50.176568: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-08-20 10:46:50.177061: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-08-20 10:46:50.180089: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-08-20 10:46:50.182418: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-08-20 10:46:50.189204: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-08-20 10:46:50.205369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1, 2, 3, 4\n",
      "2021-08-20 10:46:50.206693: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2021-08-20 10:46:50.224255: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1700085000 Hz\n",
      "2021-08-20 10:46:50.226620: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5650796f8f90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-08-20 10:46:50.226660: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_14330/1379444309.py:37: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-20 10:46:50.969803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:04:00.0\n",
      "2021-08-20 10:46:50.971380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:05:00.0\n",
      "2021-08-20 10:46:50.972887: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 2 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:08:00.0\n",
      "2021-08-20 10:46:50.974366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 3 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:09:00.0\n",
      "2021-08-20 10:46:50.976478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 4 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:89:00.0\n",
      "2021-08-20 10:46:50.976650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-08-20 10:46:50.976688: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-08-20 10:46:50.976719: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-08-20 10:46:50.976747: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-08-20 10:46:50.976776: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-08-20 10:46:50.976804: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-08-20 10:46:50.976833: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-08-20 10:46:50.995094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1, 2, 3, 4\n",
      "2021-08-20 10:46:50.995178: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-08-20 10:46:51.004358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-08-20 10:46:51.004393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 2 3 4 \n",
      "2021-08-20 10:46:51.004414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N Y Y Y N \n",
      "2021-08-20 10:46:51.004437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   Y N Y Y N \n",
      "2021-08-20 10:46:51.004449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 2:   Y Y N Y N \n",
      "2021-08-20 10:46:51.004458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 3:   Y Y Y N N \n",
      "2021-08-20 10:46:51.004468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 4:   N N N N N \n",
      "2021-08-20 10:46:51.015755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 493 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1)\n",
      "2021-08-20 10:46:51.020112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10359 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:05:00.0, compute capability: 6.1)\n",
      "2021-08-20 10:46:51.024487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10359 MB memory) -> physical GPU (device: 2, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:08:00.0, compute capability: 6.1)\n",
      "2021-08-20 10:46:51.029839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 10211 MB memory) -> physical GPU (device: 3, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:09:00.0, compute capability: 6.1)\n",
      "2021-08-20 10:46:51.033956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:4 with 10359 MB memory) -> physical GPU (device: 4, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:89:00.0, compute capability: 6.1)\n",
      "2021-08-20 10:46:51.038602: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56507b1f9260 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2021-08-20 10:46:51.038635: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2021-08-20 10:46:51.038647: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2021-08-20 10:46:51.038656: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2021-08-20 10:46:51.038664: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2021-08-20 10:46:51.038672: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (4): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.07252574 -0.42075235]\n",
      " [-1.4442182   0.44009724]]\n",
      "/device:GPU:0\n",
      "/device:GPU:1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# list 'c' in which we will append our list\n",
    "c = []\n",
    "# random initialisation of two matrices 'a' and 'b'.\n",
    "\n",
    "a = tf.get_variable(f\"a\", [2, 2], initializer=tf.random_uniform_initializer(-1, 1))\n",
    "b = tf.get_variable(f\"b\", [2, 2], initializer=tf.random_uniform_initializer(-1, 1))\n",
    "\n",
    "##### START CODE HERE  #######\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    m1 = tf.matmul(a,b)\n",
    "    c.append(m1)\n",
    "with tf.device('/gpu:1'):\n",
    "    m2 = tf.matmul(a,b)\n",
    "    c.append(m2)\n",
    "with tf.device('/cpu:0'):\n",
    "    sum = tf.math.add(tf.matmul(a,b), tf.matmul(a,b))\n",
    "    \n",
    "'''\n",
    "HINTS :\n",
    "You have to initialise three devices as asked above (gpu-0, gpu-1, cpu-0).\n",
    "After initialisation perform the task in each f those initialisation.\n",
    "For matrix multiplication, look at above task.\n",
    "While for addition part - Find Yourself.\n",
    "'''\n",
    "\n",
    "    \n",
    "#### YOU CODE ENDS HERE   ######\n",
    "\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "print(sess.run(sum))\n",
    "print(c[0].device)\n",
    "print(c[1].device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8424057e-ffb9-4acf-b058-0d7f318e0857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct!\n",
      "Your score is now 4\n"
     ]
    }
   ],
   "source": [
    "sol.q2_check(c)  #RUn THIS CELL TO SEE IF YOU ARE CORRECT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc303a6-1b21-46d8-bd13-7e56bd19121b",
   "metadata": {},
   "source": [
    "# Now in this task you will be dealing with Data Parallelism\n",
    "We have declared two tensors a and b, you just have to complete the code so that the matrix multiplication is done in two GPUs with different set of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "982ae848-3ef5-4a06-b46a-9e2ce6d03d4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable a already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"/home/ug2019/eee/19085089/.conda/envs/multi/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n  File \"/home/ug2019/eee/19085089/.conda/envs/multi/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"/home/ug2019/eee/19085089/.conda/envs/multi/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"/home/ug2019/eee/19085089/.conda/envs/multi/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ug2019/eee/19085089/.conda/envs/multi/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14450/70370225.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"a\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [2,2,3]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"b\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/multi/lib/python3.7/site-packages/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1498\u001b[0m       \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1499\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1500\u001b[0;31m       aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/multi/lib/python3.7/site-packages/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1241\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1243\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m~/.conda/envs/multi/lib/python3.7/site-packages/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    565\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m~/.conda/envs/multi/lib/python3.7/site-packages/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    517\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     synchronization, aggregation, trainable = (\n",
      "\u001b[0;32m~/.conda/envs/multi/lib/python3.7/site-packages/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"tensorflow/python\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         raise ValueError(\"%s Originally defined at:\\n\\n%s\" %\n\u001b[0;32m--> 868\u001b[0;31m                          (err_msg, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    869\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Variable a already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"/home/ug2019/eee/19085089/.conda/envs/multi/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n  File \"/home/ug2019/eee/19085089/.conda/envs/multi/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"/home/ug2019/eee/19085089/.conda/envs/multi/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"/home/ug2019/eee/19085089/.conda/envs/multi/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ug2019/eee/19085089/.conda/envs/multi/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "c = []\n",
    "a = tf.get_variable(f\"a\", [2, 4, 3], initializer=tf.random_uniform_initializer(-1, 1))  # [2,2,3]\n",
    "b = tf.get_variable(f\"b\", [2, 3, 2], initializer=tf.random_uniform_initializer(-1, 1))\n",
    "\n",
    "# Multiple towers\n",
    "for i, d in enumerate(['/gpu:0', '/gpu:1']):   # Complete Code.\n",
    "    with tf.device(d):                        #Complete Code\n",
    "        c.append(tf.matmul(a[i], b[i]))   # Tower i is responsible for batch data i.\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    sum = tf.add_n(c)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "print(sess.run(sum))   \n",
    "print(c[0].device)\n",
    "print(c[1].device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "498e9a30-bc17-4df2-a626-c5b35f73a16f",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14450/3666310738.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq3_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/ML TALKS/gpu_optim/checker/assignment1.py\u001b[0m in \u001b[0;36mq3_check\u001b[0;34m(self, c)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mq3_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m':'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m':'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'q_3'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__fname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "sol.q3_check(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98483dbb-9c12-4c5c-8af1-e0449484f702",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "# <font color = \"red\">PANDARALLEL</font>\n",
    "In this part we practice with the pandarallel library that allows parallel processing of DataFrames. \n",
    "\n",
    "#### Note: pandarallel can speed up computation using the physical cores present, hyperthreading does not increase speed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e147c359-188a-47ca-8ca9-ce4712075566",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Run this code before attempting the excerise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2513006e-92ad-4296-a2c6-dc706ce46051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XCoordinate</th>\n",
       "      <th>YCoordinate</th>\n",
       "      <th>Color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.272539</td>\n",
       "      <td>-1.458690</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.315128</td>\n",
       "      <td>-1.189050</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.123966</td>\n",
       "      <td>-0.140817</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.973588</td>\n",
       "      <td>-0.448993</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.532828</td>\n",
       "      <td>-0.181980</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   XCoordinate  YCoordinate  Color\n",
       "0    -0.272539    -1.458690   Blue\n",
       "1     0.315128    -1.189050   Blue\n",
       "2     2.123966    -0.140817   Blue\n",
       "3     0.973588    -0.448993  Green\n",
       "4     0.532828    -0.181980    Red"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "\n",
    "tqdm.pandas()\n",
    "size = int(5e6)\n",
    "\n",
    "# Synthetic dataset of random points\n",
    "df = pd.DataFrame({\n",
    "    'XCoordinate': np.random.randn(size),\n",
    "    'YCoordinate': np.random.randn(size),\n",
    "    'Color': np.random.choice(['Red','Blue','Green'],size)\n",
    "})\n",
    "# Preview of dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b57ba2e-d44e-451b-8668-7132c4a11c94",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "For starters you have to first import the `pandarallel` class from the pandarallel module and run the `initialize()` method of the class. You can pass `progress_bar=True` to `initialize()` if you want to see progress bars.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0baac3c1-f93e-406b-91e3-c4c528706247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/home/ug2019/eee/19085089/.conda/envs/multi/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/home/ug2019/eee/19085089/.conda/envs/multi/lib/python3.7/site-packages)\u001b[0m\n",
      "Requirement already satisfied: pandarallel in /home/ug2019/eee/19085089/.conda/envs/multi/lib/python3.7/site-packages (1.5.2)\n",
      "Requirement already satisfied: dill in /home/ug2019/eee/19085089/.conda/envs/multi/lib/python3.7/site-packages (from pandarallel) (0.3.4)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/home/ug2019/eee/19085089/.conda/envs/multi/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/home/ug2019/eee/19085089/.conda/envs/multi/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/home/ug2019/eee/19085089/.conda/envs/multi/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/home/ug2019/eee/19085089/.conda/envs/multi/lib/python3.7/site-packages)\u001b[0m\n",
      "INFO: Pandarallel will run on 16 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "!pip install pandarallel\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(shm_size_mb=None, progress_bar=True, verbose=2,use_memory_fs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "870559f6-a74a-4026-b17a-eeac22697bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct!\n",
      "Your score is now 5\n"
     ]
    }
   ],
   "source": [
    "sol.q4_check(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40b72ce-52a4-4f84-8675-871719cde59f",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "We have defined the function `l1_norm` here that takes a row in the `DataFrame` as argument and returns the L1 Norm of the point, i.e sum of absolute values of the coordinates. Run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79971c78-9bca-49a3-a3a5-e21c623932ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6ce0f37-b10a-44fc-bda2-1cfdd49740ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_norm(row):\n",
    "      return row.XCoordinate + row.YCoordinate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be387d1b-eae8-452c-b5e7-c297f4754c12",
   "metadata": {},
   "source": [
    "Next we will apply the function to each row by calling the `progress_apply()` method on the `DataFrame`. This may take a minute or two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf41df2e-a514-48ef-aadd-d1ab678da9e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "752ed962e0e64801a08fec682d49cd26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171.67378568649292\n",
      "CPU times: user 2min 50s, sys: 2.83 s, total: 2min 53s\n",
      "Wall time: 2min 51s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XCoordinate</th>\n",
       "      <th>YCoordinate</th>\n",
       "      <th>Color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.272539</td>\n",
       "      <td>-1.458690</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.315128</td>\n",
       "      <td>-1.189050</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.123966</td>\n",
       "      <td>-0.140817</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.973588</td>\n",
       "      <td>-0.448993</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.532828</td>\n",
       "      <td>-0.181980</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   XCoordinate  YCoordinate  Color\n",
       "0    -0.272539    -1.458690   Blue\n",
       "1     0.315128    -1.189050   Blue\n",
       "2     2.123966    -0.140817   Blue\n",
       "3     0.973588    -0.448993  Green\n",
       "4     0.532828    -0.181980    Red"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "seq_time = time.time()\n",
    "\n",
    "seq = df.progress_apply(l1_norm,axis=1)\n",
    "\n",
    "seq_time = time.time() - seq_time\n",
    "print(seq_time)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7c402b-ed7d-4b26-a644-0b62bbdc9b2d",
   "metadata": {},
   "source": [
    "Now your task is to process each row with the same function but now \n",
    "\n",
    "using parallel processing provided with the help of `pandarallel` . You can compre the time with the previous execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a43b6405-8ccc-4488-b699-c9f5f8a333d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb43926a3b2a462fb0d8759b337caaac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=312500), Label(value='0 / 312500')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.382317543029785\n",
      "CPU times: user 2.92 s, sys: 999 ms, total: 3.92 s\n",
      "Wall time: 13.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0   -1.731229\n",
       "1   -0.873922\n",
       "2    1.983149\n",
       "3    0.524596\n",
       "4    0.350848\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "par_time = time.time()\n",
    "\n",
    "par = df.parallel_apply(l1_norm,axis=1,raw=False,result_type=None,args=())\n",
    "\n",
    "par_time = time.time() - par_time\n",
    "print(par_time)\n",
    "par.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c383692-d647-4500-b6fa-844e6d117b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct!\n",
      "Your score is now 5\n"
     ]
    }
   ],
   "source": [
    "sol.q5_check(seq,seq_time,par,par_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e0c442-ff58-4c6a-89e7-fdc95f3a48ba",
   "metadata": {},
   "source": [
    "Now hopefully you can appreciate the \n",
    "reduction in time offered by the parallel processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16f74ba-54e8-4e88-a1c6-2c8e55bf0db5",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "This is a bonus task for your learning. It is not necessary that you solve this, but give it a try\n",
    "\n",
    "In this step what you have to is to use what you have learned and add a column `ORD_Color` to the dataset containing the ordinal encoding of the `'Color'` column, you must use parallel processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "267005b7-4a11-43eb-86bc-54376fba4eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b6a5015059a45ec9c3450126bfbd04a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=312500), Label(value='0 / 312500')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.298821210861206\n",
      "CPU times: user 3.1 s, sys: 1.16 s, total: 4.26 s\n",
      "Wall time: 14.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0   -1.731229\n",
       "1   -0.873922\n",
       "2    1.983149\n",
       "3    0.524596\n",
       "4    0.350848\n",
       "Name: ORD_Color, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "par_time = time.time()\n",
    "\n",
    "df['ORD_Color'] = df.parallel_apply(l1_norm,axis=1,raw=False,result_type=None,args=())\n",
    "\n",
    "par_time = time.time() - par_time\n",
    "print(par_time)\n",
    "df['ORD_Color'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42c51f3e-e294-4d7b-a679-03b8d7043847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XCoordinate</th>\n",
       "      <th>YCoordinate</th>\n",
       "      <th>Color</th>\n",
       "      <th>ORD_Color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.272539</td>\n",
       "      <td>-1.458690</td>\n",
       "      <td>Blue</td>\n",
       "      <td>-1.731229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.315128</td>\n",
       "      <td>-1.189050</td>\n",
       "      <td>Blue</td>\n",
       "      <td>-0.873922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.123966</td>\n",
       "      <td>-0.140817</td>\n",
       "      <td>Blue</td>\n",
       "      <td>1.983149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.973588</td>\n",
       "      <td>-0.448993</td>\n",
       "      <td>Green</td>\n",
       "      <td>0.524596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.532828</td>\n",
       "      <td>-0.181980</td>\n",
       "      <td>Red</td>\n",
       "      <td>0.350848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   XCoordinate  YCoordinate  Color  ORD_Color\n",
       "0    -0.272539    -1.458690   Blue  -1.731229\n",
       "1     0.315128    -1.189050   Blue  -0.873922\n",
       "2     2.123966    -0.140817   Blue   1.983149\n",
       "3     0.973588    -0.448993  Green   0.524596\n",
       "4     0.532828    -0.181980    Red   0.350848"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d70c6c-4f53-4d4e-8a27-c67f64ec2de9",
   "metadata": {},
   "source": [
    "<font color = \"Red\"><B><h1>Mult Threading and Multi Processing</h1></B></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffff5841-5da3-4034-9c5f-a3db3098e5b0",
   "metadata": {},
   "source": [
    "Before moving further, run the cell below to have an basic idea of Threading in Python.<br>\n",
    "Here, in this code we have made three separate threads - \n",
    "1. The main Thread\n",
    "2. t1 thread\n",
    "3. t2 thread\n",
    "\n",
    "t1 thread is responsible for printing 'Hello' while the t2 thread is responsible for 'Hi' and the main thread is the main thread, here in this case it is reponsible for printing 'Bye'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "40b453b8-9ab7-4363-89d6-2878203922f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "Hi\n",
      "Hello\n",
      "Hi\n",
      "Hello\n",
      "Hi\n",
      "Hello\n",
      "Hi\n",
      "Hello\n",
      "Hi\n",
      "Bye\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nBonus Task:\\nWith the help of multiprocessing module of python, try to initialise the 't1' and \\n't2' as Process() [ as did in commented code ], and so try to improve the functionality of this code.\\nWatch this video to get more idea -\\n'https://www.youtube.com/watch?v=fKl2JW_qrso'\\n\\n\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The first imports the sleep function from time module- it is used wait at the line for a given time.\n",
    "## The second line is to import the inbuilt 'Threading' module of Python.\n",
    "from time import sleep \n",
    "from threading import *\n",
    "class demo():\n",
    "\n",
    "    class Hello(Thread):\n",
    "          def run(self):  \n",
    "            for i in range(5):\n",
    "              print(\"Hello\")\n",
    "              sleep(1)  # waits for 1 milli seconds at this line.\n",
    "\n",
    "    class Hi(Thread):\n",
    "          def run(self):\n",
    "            for i in range(5):\n",
    "              print(\"Hi\")\n",
    "              sleep(1)\n",
    "\n",
    "    t1 = Hello()\n",
    "    t2 = Hi()\n",
    "\n",
    "    t1.start()   # calls the run function of t1 class (Hello class). \n",
    "    sleep(0.2)\n",
    "    t2.start()   # calls the run function of the t2 class (Hi class).\n",
    "\n",
    "    '''\n",
    "    The below lines are helpful in executing the t1 thread and t2 thread first before the \n",
    "    execution of Main Thread. To understand more clearly, just comment out the two lines \n",
    "    and then run the cell to see the difference.\n",
    "    '''\n",
    "    t1.join()\n",
    "    t2.join()\n",
    "\n",
    "    print(\"Bye\")\n",
    "\n",
    "demo()\n",
    "\n",
    "'''\n",
    "If you want to explore more: We have a small piece of code for your help:\n",
    "Just uncomment it and run it in a different cell.\n",
    "'''\n",
    "#: Hope you remember the Process function from the slides !\n",
    "\n",
    "# from multiprocessing import Process   \n",
    "\n",
    "# def f(name):\n",
    "#     print('hello', name)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     p = Process(target=f, args=('bob',))\n",
    "#     p.start()\n",
    "#     p.join()\n",
    "\n",
    "'''\n",
    "Bonus Task:\n",
    "With the help of multiprocessing module of python, try to initialise the 't1' and \n",
    "'t2' as Process() [ as did in commented code ], and so try to improve the functionality of this code.\n",
    "Watch this video to get more idea -\n",
    "'https://www.youtube.com/watch?v=fKl2JW_qrso'\n",
    "\n",
    "'''\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a0ac76-c71a-46bc-8068-c3169fc5c005",
   "metadata": {},
   "source": [
    "# In this task you have to literally do nothing !\n",
    "# You just have to tweak the range of the iteration(the for loop) to figure out the relationship between the overall time taken to perform the task and the computation complexity of the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2fd28b30-a09b-47b1-a94d-c8585951c11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pool time =  1.0259582996368408\n",
      "Serial Processing time =  5.085031747817993\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Run the below code to get an intution of what is happenening, here.\n",
    "'''\n",
    "\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "\n",
    "\n",
    "def square_add(x):\n",
    "      sum = 0\n",
    "      for j in range(2000):\n",
    "        sum += j*j\n",
    "      return sum\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "          toc = time.time()\n",
    "          p = Pool()\n",
    "          result = p.map(square_add, range(20000))\n",
    "          p.close()\n",
    "          p.join()\n",
    "          tic = time.time()\n",
    "          print(\"Pool time = \", tic-toc)\n",
    "\n",
    "          toc = time.time()\n",
    "          result = []\n",
    "\n",
    "          for i in range(20000):\n",
    "                  result.append(square_add(i))\n",
    "          tic = time.time()\n",
    "          print(\"Serial Processing time = \", tic-toc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24539ad-adc6-4783-9544-10eb883f4922",
   "metadata": {},
   "source": [
    "# The Task below is designed to get your hands on the type of Shared Memory among processes as discussed in the slides.<br>\n",
    "Read the INSTRUCTIONS carefully to get an idea of your task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e71609d-b6fb-4449-9226-791af9a68a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[4, 9, 25]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Task7 at 0x7f079df2e780>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "INSTRUCTIONS:\n",
    "1. FIRST of all COMMENT the four line of codes (as instructed).\n",
    "2. Once done that run the cell to see the output. Now, UNCOMMENT the said four lines.\n",
    "3. Now, run the cell and see the output.\n",
    "4. You might have noticed the difference in output-in one case you have blank array while you got filled array in other case.\n",
    "5. The reason behind this was - those four lines just make the memory sharing possible between the two processes.\n",
    "6. One in he main process (under the if __name__ == \"__main__: command) and the other is in the 'getSquare' function.\n",
    "7. This is called 'queue pipe Multiprocessing'.\n",
    "\n",
    "YOUR TASK:\n",
    "1. Create a function named 'getNumSquare'. In this function you will take one argument 'num'\n",
    "2. This 'num' is a shared Memory of type 'value' and is to be declared as 'double'.\n",
    "3. You just have to assign a real number to the 'num' variable inside the function and get it printed \n",
    "  in the 'if statement' (if __name_ == \"__main__\")\n",
    "4. We have added multiprocessing.active_children() for you in the bottom of code which prints number of active workers.\n",
    "5. You job is to just add 1 line of code to get the numbers of CPU in the system.(There is a inbulit function for this).\n",
    "\n",
    "BONUS TASK:\n",
    "1. Repeat the same task for a Queue type shared Memory in a new cell.\n",
    "2. You have to use queue.put()- to put the numbers in a variable named 'queue' of type Queue.\n",
    "3. Also queue.get() - to fetch the data in the queue.\n",
    "''' \n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "class Task7():\n",
    "    \n",
    "    def getSquares(numbers, result):    \n",
    "          for index, num in enumerate(numbers):\n",
    "                result[index] = num*num\n",
    "          eval = result\n",
    "          return eval\n",
    "   \n",
    "\n",
    "    if __name__ == \"__main__\":\n",
    "          numbers = [2,3,5]\n",
    "          result = []\n",
    "\n",
    "          ###  COMMENT FOUR LINES BELOW  ####\n",
    "          result = multiprocessing.Array('i', 3)\n",
    "          p = multiprocessing.Process(target=getSquares, args=(numbers, result))\n",
    "          #p = threading.Thread(target = getSquares, args = (numbers, result ))\n",
    "\n",
    "          p.start()\n",
    "          p.join() \n",
    "          \n",
    "\n",
    "          #### THE FOUR LINES TO BE COMMENTED   #######\n",
    "          \n",
    "          print(multiprocessing.active_children())\n",
    "          #print\n",
    "          print(result[:])\n",
    "    \n",
    "Task7()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6c209a2-8504-4d51-907e-31b264ca6f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "10.240000000000002\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Task7 at 0x7f42cc5d00f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "INSTRUCTIONS:\n",
    "1. FIRST of all COMMENT the four line of codes (as instructed).\n",
    "2. Once done that run the cell to see the output. Now, UNCOMMENT the said four lines.\n",
    "3. Now, run the cell and see the output.\n",
    "4. You might have noticed the difference in output-in one case you have blank array while you got filled array in other case.\n",
    "5. The reason behind this was - those four lines just make the memory sharing possible between the two processes.\n",
    "6. One in he main process (under the if __name__ == \"__main__: command) and the other is in the 'getSquare' function.\n",
    "7. This is called 'queue pipe Multiprocessing'.\n",
    "\n",
    "YOUR TASK:\n",
    "1. Create a function named 'getNumSquare'. In this function you will take one argument 'num'\n",
    "2. This 'num' is a shared Memory of type 'value' and is to be declared as 'double'.\n",
    "3. You just have to assign a real number to the 'num' variable inside the function and get it printed \n",
    "  in the 'if statement' (if __name_ == \"__main__\")\n",
    "4. We have added multiprocessing.active_children() for you in the bottom of code which prints number of active workers.\n",
    "5. You job is to just add 1 line of code to get the numbers of CPU in the system.(There is a inbulit function for this).\n",
    "\n",
    "BONUS TASK:\n",
    "1. Repeat the same task for a Queue type shared Memory in a new cell.\n",
    "2. You have to use queue.put()- to put the numbers in a variable named 'queue' of type Queue.\n",
    "3. Also queue.get() - to fetch the data in the queue.\n",
    "''' \n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "class Task7():\n",
    "    \n",
    "    #def getSquares(numbers, result):    \n",
    "          #for index, num in enumerate(numbers):\n",
    "                #result[index] = num*num\n",
    "          #eval = result\n",
    "          #return eval\n",
    "    def getNumSquare(num):\n",
    "        #num.value = 3.14\n",
    "        num.value = num.value**2\n",
    "        return num\n",
    "\n",
    "    if __name__ == \"__main__\":\n",
    "          num  = multiprocessing.Value('d', 3.2)\n",
    "\n",
    "          ###  COMMENT FOUR LINES BELOW  ####\n",
    "          #result = multiprocessing.Array('i', 3)\n",
    "          a = multiprocessing.Process(target=getNumSquare, args=(num,))\n",
    "          #p = threading.Thread(target = getSquares, args = (numbers, result ))\n",
    "\n",
    "          a.start()\n",
    "          a.join() \n",
    "          print(multiprocessing.cpu_count())  \n",
    "          \n",
    "\n",
    "          #### THE FOUR LINES TO BE COMMENTED   #######\n",
    "          print(num.value)\n",
    "          print(multiprocessing.active_children())\n",
    "          #print\n",
    "          #print(result[:])\n",
    "    \n",
    "Task7()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "921f3040-14c3-4f1a-87c9-e0bd689be06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.8, 4.2]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import multiprocessing\n",
    "from multiprocessing import Process, Queue\n",
    "\n",
    "def getNumSquare(q):\n",
    "    q.put([2.8, 4.2])\n",
    "    return q\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    q = Queue()\n",
    "    p = multiprocessing.Process(target=getNumSquare, args=(q,))\n",
    "    p.start()\n",
    "    print(q.get())\n",
    "    p.join()\n",
    "    \n",
    "    print(multiprocessing.cpu_count())  \n",
    "    print(multiprocessing.active_children())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
