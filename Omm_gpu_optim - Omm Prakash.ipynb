{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0182193a-0156-43f7-96cb-0d6012e4575a",
   "metadata": {
    "tags": []
   },
   "source": [
    "<B><h1><font color = \"green\" size = '20'>HANDOUT ASSIGNMENTS : </font></h1></B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d96150c-19aa-4207-a097-56ab1dc2def0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete\n"
     ]
    }
   ],
   "source": [
    "# YOU HAVE TO RUN THIS CODE EVERYTIME YOU RESTART THE KERNEL\n",
    "from checker.assignment1 import Solution\n",
    "#Enter your name in quotes with underscore for space below\n",
    "sol = Solution('Omm Prakash Sahoo')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d56c48-ff63-4839-b4fb-4370532f1515",
   "metadata": {},
   "source": [
    "<h1><B><font color = 'red'>GPU OPTIMISATION</font><B></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d9e6a5-f38e-4377-8cbd-d3f998813c2f",
   "metadata": {},
   "source": [
    "# In the below question, we want you to make some changes, so that m1, m2, product are all on the GPU \n",
    "\n",
    "# You can run the cell containing checker code to see whether you succeeded or not.\n",
    "Note : You may have to restart the kernel everytime you change the GPU, the kernel restart option is available under the kernel menu in top left.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d092a609-f262-4c01-bca8-0476256ec5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n",
      "WARNING:tensorflow:From /tmp/ipykernel_11287/1585956674.py:15: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-20 09:27:03.162824: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-08-20 09:27:03.196491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:04:00.0\n",
      "2021-08-20 09:27:03.197786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:05:00.0\n",
      "2021-08-20 09:27:03.199880: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 2 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:08:00.0\n",
      "2021-08-20 09:27:03.201741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 3 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:09:00.0\n",
      "2021-08-20 09:27:03.203808: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 4 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:89:00.0\n",
      "2021-08-20 09:27:03.204456: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-08-20 09:27:03.207402: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-08-20 09:27:03.210107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-08-20 09:27:03.210831: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-08-20 09:27:03.214369: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-08-20 09:27:03.217025: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-08-20 09:27:03.224298: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-08-20 09:27:03.238831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1, 2, 3, 4\n",
      "2021-08-20 09:27:03.240121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2021-08-20 09:27:03.253439: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1700085000 Hz\n",
      "2021-08-20 09:27:03.255777: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56132d11fa40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-08-20 09:27:03.255824: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/device:GPU:4\n",
      "/device:GPU:4\n",
      "/device:GPU:4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-20 09:27:04.024561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:04:00.0\n",
      "2021-08-20 09:27:04.025454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:05:00.0\n",
      "2021-08-20 09:27:04.027050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 2 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:08:00.0\n",
      "2021-08-20 09:27:04.028558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 3 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:09:00.0\n",
      "2021-08-20 09:27:04.030065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 4 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:89:00.0\n",
      "2021-08-20 09:27:04.030140: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-08-20 09:27:04.030166: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-08-20 09:27:04.030187: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-08-20 09:27:04.030208: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-08-20 09:27:04.030228: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-08-20 09:27:04.030249: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-08-20 09:27:04.030271: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-08-20 09:27:04.044416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1, 2, 3, 4\n",
      "2021-08-20 09:27:04.044581: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-08-20 09:27:04.052881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-08-20 09:27:04.052909: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 2 3 4 \n",
      "2021-08-20 09:27:04.052927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N Y Y Y N \n",
      "2021-08-20 09:27:04.052937: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   Y N Y Y N \n",
      "2021-08-20 09:27:04.052946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 2:   Y Y N Y N \n",
      "2021-08-20 09:27:04.052955: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 3:   Y Y Y N N \n",
      "2021-08-20 09:27:04.052964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 4:   N N N N N \n",
      "2021-08-20 09:27:04.064062: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 48 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1)\n",
      "2021-08-20 09:27:04.067060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 48 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:05:00.0, compute capability: 6.1)\n",
      "2021-08-20 09:27:04.070701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10229 MB memory) -> physical GPU (device: 2, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:08:00.0, compute capability: 6.1)\n",
      "2021-08-20 09:27:04.074699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 10081 MB memory) -> physical GPU (device: 3, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:09:00.0, compute capability: 6.1)\n",
      "2021-08-20 09:27:04.078605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:4 with 10229 MB memory) -> physical GPU (device: 4, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:89:00.0, compute capability: 6.1)\n",
      "2021-08-20 09:27:04.082899: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56132ec1fd70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2021-08-20 09:27:04.082928: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2021-08-20 09:27:04.082939: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2021-08-20 09:27:04.082948: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2021-08-20 09:27:04.082957: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2021-08-20 09:27:04.082965: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (4): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "## CHANGE BELOW CODE\n",
    "\n",
    "with tf.device('/gpu:4'):\n",
    "    m1 = tf.constant([[3., 5.]])\n",
    "    m2 = tf.constant([[2.],[4.]])\n",
    "\n",
    "    product = tf.matmul(m1, m2)    # A matrix multiplication op node\n",
    "\n",
    "\n",
    "## CHANGE ABOVE CODE\n",
    "sess = tf.Session()\n",
    "\n",
    "print(product.device)\n",
    "print(m1.device)\n",
    "print(m2.device)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1852fdae-15f2-4ddb-b59e-16028fbd2d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct!\n",
      "Your score is now 1\n"
     ]
    }
   ],
   "source": [
    "sol.q1_check(m1,m2,product) #RUN THIS CELL WITHOUT CHANGE TO SEE YOUR SCORE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c86993-11a8-4fd9-8af7-fc97a79251f4",
   "metadata": {},
   "source": [
    "# In the next task, we are providing you a boiler plate code based on Model Parallelism. \n",
    "You have to complete the following task in your code:\n",
    "We have already initialised two matrix of dimension 2X2, a and b, with random values.\n",
    "Now you have to implement this three steps.\n",
    "\n",
    "\n",
    "1.   Use gpu with id '0' to perform matrix multiplication and append it in  the list 'c'.\n",
    "2.  Use gpu with id '1' to perform atrix multiplication of 'a' and 'b'. And append it in list 'c'.\n",
    "3.  Add all the matrix which you appended in list 'c' above and store result in sum. You have to use cpu with id '0' for this step.\n",
    "\n",
    "In case the gpus are not available, you can try in other gpus (id 0-4), just make sure both gpus are not the same.\n",
    "\n",
    "### Reminder: you may have to restart kernel everytime you change gpus/cpus in code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba44adb5-0007-4122-ba02-23fb927a5693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_11287/3013387629.py:8: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_11287/3013387629.py:37: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-20 09:29:50.318798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:04:00.0\n",
      "2021-08-20 09:29:50.319968: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:05:00.0\n",
      "2021-08-20 09:29:50.321809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 2 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:08:00.0\n",
      "2021-08-20 09:29:50.323391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 3 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:09:00.0\n",
      "2021-08-20 09:29:50.325225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 4 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:89:00.0\n",
      "2021-08-20 09:29:50.325295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-08-20 09:29:50.325320: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-08-20 09:29:50.325341: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-08-20 09:29:50.325361: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-08-20 09:29:50.325382: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-08-20 09:29:50.325402: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-08-20 09:29:50.325422: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-08-20 09:29:50.339524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1, 2, 3, 4\n",
      "2021-08-20 09:29:50.339617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-08-20 09:29:50.339630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 2 3 4 \n",
      "2021-08-20 09:29:50.339639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N Y Y Y N \n",
      "2021-08-20 09:29:50.339646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   Y N Y Y N \n",
      "2021-08-20 09:29:50.339654: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 2:   Y Y N Y N \n",
      "2021-08-20 09:29:50.339661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 3:   Y Y Y N N \n",
      "2021-08-20 09:29:50.339668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 4:   N N N N N \n",
      "2021-08-20 09:29:50.347941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 48 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1)\n",
      "2021-08-20 09:29:50.349032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 48 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:05:00.0, compute capability: 6.1)\n",
      "2021-08-20 09:29:50.350790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10229 MB memory) -> physical GPU (device: 2, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:08:00.0, compute capability: 6.1)\n",
      "2021-08-20 09:29:50.352299: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 10081 MB memory) -> physical GPU (device: 3, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:09:00.0, compute capability: 6.1)\n",
      "2021-08-20 09:29:50.354051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:4 with 10229 MB memory) -> physical GPU (device: 4, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:89:00.0, compute capability: 6.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.676142   -0.23477378]\n",
      " [-0.9889411  -0.31156352]]\n",
      "/device:GPU:0\n",
      "/device:GPU:1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# list 'c' in which we will append our list\n",
    "c = []\n",
    "# random initialisation of two matrices 'a' and 'b'.\n",
    "\n",
    "a = tf.get_variable(f\"a\", [2, 2], initializer=tf.random_uniform_initializer(-1, 1))\n",
    "b = tf.get_variable(f\"b\", [2, 2], initializer=tf.random_uniform_initializer(-1, 1))\n",
    "\n",
    "##### START CODE HERE  #######\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    m1 = tf.matmul(a,b)\n",
    "    c.append(m1)\n",
    "with tf.device('/gpu:1'):\n",
    "    m2 = tf.matmul(a,b)\n",
    "    c.append(m2)\n",
    "with tf.device('/cpu:0'):\n",
    "    sum = tf.math.add(tf.matmul(a,b),tf.matmul(a,b))\n",
    "    \n",
    "'''\n",
    "HINTS :\n",
    "You have to initialise three devices as asked above (gpu-0, gpu-1, cpu-0).\n",
    "After initialisation perform the task in each f those initialisation.\n",
    "For matrix multiplication, look at above task.\n",
    "While for addition part - Find Yourself.\n",
    "'''\n",
    "\n",
    "    \n",
    "#### YOU CODE ENDS HERE   ######\n",
    "\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "print(sess.run(sum))\n",
    "print(c[0].device)\n",
    "print(c[1].device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8424057e-ffb9-4acf-b058-0d7f318e0857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct!\n",
      "Your score is now 2\n"
     ]
    }
   ],
   "source": [
    "sol.q2_check(c)  #RUn THIS CELL TO SEE IF YOU ARE CORRECT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc303a6-1b21-46d8-bd13-7e56bd19121b",
   "metadata": {},
   "source": [
    "# Now in this task you will be dealing with Data Parallelism\n",
    "We have declared two tensors a and b, you just have to complete the code so that the matrix multiplication is done in two GPUs with different set of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "982ae848-3ef5-4a06-b46a-9e2ce6d03d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_13984/3944838785.py:6: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /tmp/ipykernel_13984/3944838785.py:17: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-20 11:00:07.815169: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-08-20 11:00:07.845708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:04:00.0\n",
      "2021-08-20 11:00:07.847515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:05:00.0\n",
      "2021-08-20 11:00:07.849206: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 2 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:08:00.0\n",
      "2021-08-20 11:00:07.850638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 3 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:09:00.0\n",
      "2021-08-20 11:00:07.852385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 4 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:89:00.0\n",
      "2021-08-20 11:00:07.852943: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-08-20 11:00:07.855545: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-08-20 11:00:07.857988: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-08-20 11:00:07.858598: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-08-20 11:00:07.861635: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-08-20 11:00:07.864028: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-08-20 11:00:07.870731: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-08-20 11:00:07.886108: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1, 2, 3, 4\n",
      "2021-08-20 11:00:07.887528: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2021-08-20 11:00:07.904238: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1700085000 Hz\n",
      "2021-08-20 11:00:07.906394: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564cf50413c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-08-20 11:00:07.906437: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_13984/3944838785.py:19: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-20 11:00:08.667535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:04:00.0\n",
      "2021-08-20 11:00:08.669079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:05:00.0\n",
      "2021-08-20 11:00:08.670586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 2 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:08:00.0\n",
      "2021-08-20 11:00:08.672069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 3 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:09:00.0\n",
      "2021-08-20 11:00:08.673562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 4 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:89:00.0\n",
      "2021-08-20 11:00:08.673636: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-08-20 11:00:08.673664: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-08-20 11:00:08.673688: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-08-20 11:00:08.673711: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-08-20 11:00:08.673733: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-08-20 11:00:08.673755: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-08-20 11:00:08.673778: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-08-20 11:00:08.689064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1, 2, 3, 4\n",
      "2021-08-20 11:00:08.689135: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-08-20 11:00:08.696478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-08-20 11:00:08.696506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 2 3 4 \n",
      "2021-08-20 11:00:08.696524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N Y Y Y N \n",
      "2021-08-20 11:00:08.696534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   Y N Y Y N \n",
      "2021-08-20 11:00:08.696542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 2:   Y Y N Y N \n",
      "2021-08-20 11:00:08.696551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 3:   Y Y Y N N \n",
      "2021-08-20 11:00:08.696560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 4:   N N N N N \n",
      "2021-08-20 11:00:08.707207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 493 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1)\n",
      "2021-08-20 11:00:08.710633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10359 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:05:00.0, compute capability: 6.1)\n",
      "2021-08-20 11:00:08.714502: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10359 MB memory) -> physical GPU (device: 2, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:08:00.0, compute capability: 6.1)\n",
      "2021-08-20 11:00:08.718346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 10211 MB memory) -> physical GPU (device: 3, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:09:00.0, compute capability: 6.1)\n",
      "2021-08-20 11:00:08.723812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:4 with 10359 MB memory) -> physical GPU (device: 4, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:89:00.0, compute capability: 6.1)\n",
      "2021-08-20 11:00:08.729155: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564cf6b415a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2021-08-20 11:00:08.729189: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2021-08-20 11:00:08.729201: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2021-08-20 11:00:08.729210: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2021-08-20 11:00:08.729219: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2021-08-20 11:00:08.729228: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (4): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2021-08-20 11:00:09.432625: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.08615386  1.3127123 ]\n",
      " [ 0.02853116 -0.6866784 ]\n",
      " [-1.3811271  -0.137461  ]\n",
      " [ 0.13908207  0.5172498 ]]\n",
      "/device:GPU:0\n",
      "/device:GPU:1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "c = []\n",
    "a = tf.get_variable(f\"a\", [2, 4, 3], initializer=tf.random_uniform_initializer(-1, 1))  # [2,2,3]\n",
    "b = tf.get_variable(f\"b\", [2, 3, 2], initializer=tf.random_uniform_initializer(-1, 1))\n",
    "\n",
    "# Multiple towers\n",
    "for i, d in enumerate(['/gpu:0','/gpu:1']):   # Complete Code.\n",
    "    with tf.device(d):                        #Complete Code\n",
    "        c.append(tf.matmul(a[i], b[i]))   # Tower i is responsible for batch data i.\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    sum = tf.add_n(c)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "print(sess.run(sum))   \n",
    "print(c[0].device)\n",
    "print(c[1].device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "498e9a30-bc17-4df2-a626-c5b35f73a16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct!\n",
      "Your score is now 4\n"
     ]
    }
   ],
   "source": [
    "sol.q3_check(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98483dbb-9c12-4c5c-8af1-e0449484f702",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "# <font color = \"red\">PANDARALLEL</font>\n",
    "In this part we practice with the pandarallel library that allows parallel processing of DataFrames. \n",
    "\n",
    "#### Note: pandarallel can speed up computation using the physical cores present, hyperthreading does not increase speed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e147c359-188a-47ca-8ca9-ce4712075566",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Run this code before attempting the excerise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2513006e-92ad-4296-a2c6-dc706ce46051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XCoordinate</th>\n",
       "      <th>YCoordinate</th>\n",
       "      <th>Color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002304</td>\n",
       "      <td>0.037775</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.480651</td>\n",
       "      <td>1.777255</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.605392</td>\n",
       "      <td>1.245914</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.239349</td>\n",
       "      <td>0.016084</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.673380</td>\n",
       "      <td>0.559910</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   XCoordinate  YCoordinate  Color\n",
       "0     0.002304     0.037775    Red\n",
       "1     0.480651     1.777255   Blue\n",
       "2     0.605392     1.245914    Red\n",
       "3     0.239349     0.016084  Green\n",
       "4     0.673380     0.559910    Red"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "\n",
    "tqdm.pandas()\n",
    "size = int(5e6)\n",
    "\n",
    "# Synthetic dataset of random points\n",
    "df = pd.DataFrame({\n",
    "    'XCoordinate': np.random.randn(size),\n",
    "    'YCoordinate': np.random.randn(size),\n",
    "    'Color': np.random.choice(['Red','Blue','Green'],size)\n",
    "})\n",
    "# Preview of dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b57ba2e-d44e-451b-8668-7132c4a11c94",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "For starters you have to first import the `pandarallel` class from the pandarallel module and run the `initialize()` method of the class. You can pass `progress_bar=True` to `initialize()` if you want to see progress bars.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0baac3c1-f93e-406b-91e3-c4c528706247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/home/ug2019/eee/19085089/.conda/envs/multi/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/home/ug2019/eee/19085089/.conda/envs/multi/lib/python3.7/site-packages)\u001b[0m\n",
      "Requirement already satisfied: pandarallel in /home/ug2019/eee/19085089/.conda/envs/multi/lib/python3.7/site-packages (1.5.2)\n",
      "Requirement already satisfied: dill in /home/ug2019/eee/19085089/.conda/envs/multi/lib/python3.7/site-packages (from pandarallel) (0.3.4)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/home/ug2019/eee/19085089/.conda/envs/multi/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/home/ug2019/eee/19085089/.conda/envs/multi/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/home/ug2019/eee/19085089/.conda/envs/multi/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/home/ug2019/eee/19085089/.conda/envs/multi/lib/python3.7/site-packages)\u001b[0m\n",
      "INFO: Pandarallel will run on 16 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "!pip install pandarallel\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "870559f6-a74a-4026-b17a-eeac22697bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct!\n",
      "Your score is now 5\n"
     ]
    }
   ],
   "source": [
    "sol.q4_check(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40b72ce-52a4-4f84-8675-871719cde59f",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "We have defined the function `l1_norm` here that takes a row in the `DataFrame` as argument and returns the L1 Norm of the point, i.e sum of absolute values of the coordinates. Run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6ce0f37-b10a-44fc-bda2-1cfdd49740ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_norm(row):\n",
    "      return row.XCoordinate + row.YCoordinate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be387d1b-eae8-452c-b5e7-c297f4754c12",
   "metadata": {},
   "source": [
    "Next we will apply the function to each row by calling the `progress_apply()` method on the `DataFrame`. This may take a minute or two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf41df2e-a514-48ef-aadd-d1ab678da9e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be5cbdcbaee54b84922539b2cd681ccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170.60150742530823\n",
      "CPU times: user 2min 49s, sys: 3.15 s, total: 2min 52s\n",
      "Wall time: 2min 50s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XCoordinate</th>\n",
       "      <th>YCoordinate</th>\n",
       "      <th>Color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.588972</td>\n",
       "      <td>-1.328574</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.588742</td>\n",
       "      <td>-1.786857</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.137766</td>\n",
       "      <td>0.398662</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.580650</td>\n",
       "      <td>-0.317087</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.206229</td>\n",
       "      <td>1.041174</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   XCoordinate  YCoordinate Color\n",
       "0     1.588972    -1.328574  Blue\n",
       "1    -1.588742    -1.786857   Red\n",
       "2    -2.137766     0.398662   Red\n",
       "3     0.580650    -0.317087   Red\n",
       "4     0.206229     1.041174  Blue"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "seq_time = time.time()\n",
    "\n",
    "seq = df.progress_apply(l1_norm,axis=1)\n",
    "\n",
    "seq_time = time.time() - seq_time\n",
    "print(seq_time)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7c402b-ed7d-4b26-a644-0b62bbdc9b2d",
   "metadata": {},
   "source": [
    "Now your task is to process each row with the same function but now \n",
    "\n",
    "using parallel processing provided with the help of `pandarallel` . You can compre the time with the previous execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a43b6405-8ccc-4488-b699-c9f5f8a333d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86638aee2cb94b7fac8377627ca56eaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=312500), Label(value='0 / 312500')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.05150818824768\n",
      "CPU times: user 2.96 s, sys: 1.16 s, total: 4.12 s\n",
      "Wall time: 14.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.260397\n",
       "1   -3.375598\n",
       "2   -1.739104\n",
       "3    0.263563\n",
       "4    1.247403\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "par_time = time.time()\n",
    "\n",
    "par = df.parallel_apply(l1_norm,axis = 1)\n",
    "\n",
    "par_time = time.time() - par_time\n",
    "print(par_time)\n",
    "par.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c383692-d647-4500-b6fa-844e6d117b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct!\n",
      "Your score is now 3\n"
     ]
    }
   ],
   "source": [
    "sol.q5_check(seq,seq_time,par,par_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e0c442-ff58-4c6a-89e7-fdc95f3a48ba",
   "metadata": {},
   "source": [
    "Now hopefully you can appreciate the \n",
    "reduction in time offered by the parallel processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16f74ba-54e8-4e88-a1c6-2c8e55bf0db5",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "This is a bonus task for your learning. It is not necessary that you solve this, but give it a try\n",
    "\n",
    "In this step what you have to is to use what you have learned and add a column `ORD_Color` to the dataset containing the ordinal encoding of the `'Color'` column, you must use parallel processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "267005b7-4a11-43eb-86bc-54376fba4eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49282323d1be411593aea0dd768f2a56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=312500), Label(value='0 / 312500')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b0d816b4cf74d5d90439cd7f605b1ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Time Taken by Parallel Process:  2.6641557216644287\n",
      "\n",
      "\n",
      "Time Taken by Progress Process:  12.309116840362549\n",
      "<bound method NDFrame.head of          XCoordinate  YCoordinate  Color  ORD_Color\n",
      "0           1.588972    -1.328574   Blue          1\n",
      "1          -1.588742    -1.786857    Red          0\n",
      "2          -2.137766     0.398662    Red          0\n",
      "3           0.580650    -0.317087    Red          0\n",
      "4           0.206229     1.041174   Blue          1\n",
      "...              ...          ...    ...        ...\n",
      "4999995    -1.040338    -0.156188   Blue          1\n",
      "4999996     2.245713     0.526323   Blue          1\n",
      "4999997    -0.141502     0.009195  Green          2\n",
      "4999998    -0.540701    -0.735177   Blue          1\n",
      "4999999     1.075812    -0.107800    Red          0\n",
      "\n",
      "[5000000 rows x 4 columns]>\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "def encode(txt):\n",
    "  if txt == 'Red':\n",
    "    return 0\n",
    "  if txt == 'Blue':\n",
    "    return 1\n",
    "  if txt == 'Green':\n",
    "    return 2\n",
    "\n",
    "import time\n",
    "temp = time.time()\n",
    "\n",
    "df['ORD_Color'] = df.Color.parallel_apply(encode)\n",
    "temp = time.time()-temp\n",
    "temp1 = time.time()\n",
    "\n",
    "df['ORD_Color'] = df.Color.progress_apply(encode)\n",
    "temp1 = time.time()-temp1\n",
    "\n",
    "print('\\n\\nTime Taken by Parallel Process: ',temp)\n",
    "print('\\n\\nTime Taken by Progress Process: ',temp1)\n",
    "\n",
    "print(df.head)\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d70c6c-4f53-4d4e-8a27-c67f64ec2de9",
   "metadata": {},
   "source": [
    "<font color = \"Red\"><B><h1>Mult Threading and Multi Processing</h1></B></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffff5841-5da3-4034-9c5f-a3db3098e5b0",
   "metadata": {},
   "source": [
    "Before moving further, run the cell below to have an basic idea of Threading in Python.<br>\n",
    "Here, in this code we have made three separate threads - \n",
    "1. The main Thread\n",
    "2. t1 thread\n",
    "3. t2 thread\n",
    "\n",
    "t1 thread is responsible for printing 'Hello' while the t2 thread is responsible for 'Hi' and the main thread is the main thread, here in this case it is reponsible for printing 'Bye'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40b453b8-9ab7-4363-89d6-2878203922f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "Hi\n",
      "Hello\n",
      "Hi\n",
      "Hello\n",
      "Hi\n",
      "Hello\n",
      "Hi\n",
      "Hello\n",
      "Hi\n",
      "Bye\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nBonus Task:\\nWith the help of multiprocessing module of python, try to initialise the 't1' and \\n't2' as Process() [ as did in commented code ], and so try to improve the functionality of this code.\\nWatch this video to get more idea -\\n'https://www.youtube.com/watch?v=fKl2JW_qrso'\\n\\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The first imports the sleep function from time module- it is used wait at the line for a given time.\n",
    "## The second line is to import the inbuilt 'Threading' module of Python.\n",
    "from time import sleep \n",
    "from threading import *\n",
    "class demo():\n",
    "\n",
    "    class Hello(Thread):\n",
    "          def run(self):  \n",
    "            for i in range(5):\n",
    "              print(\"Hello\")\n",
    "              sleep(1)  # waits for 1 milli seconds at this line.\n",
    "\n",
    "    class Hi(Thread):\n",
    "          def run(self):\n",
    "            for i in range(5):\n",
    "              print(\"Hi\")\n",
    "              sleep(1)\n",
    "\n",
    "    t1 = Hello()\n",
    "    t2 = Hi()\n",
    "\n",
    "    t1.start()   # calls the run function of t1 class (Hello class). \n",
    "    sleep(0.2)\n",
    "    t2.start()   # calls the run function of the t2 class (Hi class).\n",
    "\n",
    "    '''\n",
    "    The below lines are helpful in executing the t1 thread and t2 thread first before the \n",
    "    execution of Main Thread. To understand more clearly, just comment out the two lines \n",
    "    and then run the cell to see the difference.\n",
    "    '''\n",
    "    t1.join()\n",
    "    t2.join()\n",
    "\n",
    "    print(\"Bye\")\n",
    "\n",
    "demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5337df15-d6db-4ba0-8d61-8f0a50a607c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello bob\n",
      "hello Omm\n",
      "hello Ops\n",
      "Time taken: 0.12514162063598633\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "If you want to explore more: We have a small piece of code for your help:\n",
    "Just uncomment it and run it in a different cell.\n",
    "'''\n",
    "#: Hope you remember the Process function from the slides !\n",
    "\n",
    "from multiprocessing import Process   \n",
    "\n",
    "def f(name):\n",
    "    print('hello', name)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    p = Process(target=f, args=('bob',))\n",
    "    p.start()\n",
    "    p.join()\n",
    "\n",
    "'''\n",
    "Bonus Task:\n",
    "With the help of multiprocessing module of python, try to initialise the 't1' and \n",
    "'t2' as Process() [ as did in commented code ], and so try to improve the functionality of this code.\n",
    "Watch this video to get more idea -\n",
    "'https://www.youtube.com/watch?v=fKl2JW_qrso'\n",
    "\n",
    "'''\n",
    "import time\n",
    "import multiprocessing \n",
    "\n",
    "temp = time.time()\n",
    "t1 = multiprocessing.Process(target = f,args = ('Omm',))\n",
    "t2 = multiprocessing.Process(target = f,args = ('Ops',))\n",
    "\n",
    "t1.start()\n",
    "t2.start()\n",
    "\n",
    "t1.join()\n",
    "t2.join()\n",
    "\n",
    "temp = time.time()-temp\n",
    "print(f'Time taken: {temp}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a0ac76-c71a-46bc-8068-c3169fc5c005",
   "metadata": {},
   "source": [
    "# In this task you have to literally do nothing !\n",
    "# You just have to tweak the range of the iteration(the for loop) to figure out the relationship between the overall time taken to perform the task and the computation complexity of the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2fd28b30-a09b-47b1-a94d-c8585951c11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pool time =  0.729841947555542\n",
      "Serial Processing time =  0.00014734268188476562\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Run the below code to get an intution of what is happenening, here.\n",
    "'''\n",
    "\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "\n",
    "\n",
    "def square_add(x):\n",
    "      sum = 0\n",
    "      for j in range(1000):\n",
    "        sum += j*j\n",
    "      return sum\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "          toc = time.time()\n",
    "          p = Pool()\n",
    "          result = p.map(square_add, range(1))\n",
    "          p.close()\n",
    "          p.join()\n",
    "          \n",
    "          tic = time.time()\n",
    "          print(\"Pool time = \", tic-toc)\n",
    "\n",
    "          toc = time.time()\n",
    "          result = []\n",
    "\n",
    "          for i in range(1):\n",
    "                  result.append(square_add(i))\n",
    "          tic = time.time()\n",
    "          print(\"Serial Processing time = \", tic-toc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24539ad-adc6-4783-9544-10eb883f4922",
   "metadata": {},
   "source": [
    "# The Task below is designed to get your hands on the type of Shared Memory among processes as discussed in the slides.<br>\n",
    "Read the INSTRUCTIONS carefully to get an idea of your task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e71609d-b6fb-4449-9226-791af9a68a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-17:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ug2019/eee/19085089/.conda/envs/multi/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ug2019/eee/19085089/.conda/envs/multi/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_13984/1496667056.py\", line 31, in getNumsquare\n",
      "    num.value=random.randint(10,20)\n",
      "NameError: name 'random' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[4, 9, 25]\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Task7 at 0x7fe0faf1e4a8>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "INSTRUCTIONS:\n",
    "1. FIRST of all COMMENT the four line of codes (as instructed).\n",
    "2. Once done that run the cell to see the output. Now, UNCOMMENT the said four lines.\n",
    "3. Now, run the cell and see the output.\n",
    "4. You might have noticed the difference in output-in one case you have blank array while you got filled array in other case.\n",
    "5. The reason behind this was - those four lines just make the memory sharing possible between the two processes.\n",
    "6. One in he main process (under the if __name__ == \"__main__: command) and the other is in the 'getSquare' function.\n",
    "7. This is called 'queue pipe Multiprocessing'.\n",
    "\n",
    "YOUR TASK:\n",
    "1. Create a function named 'getNumSquare'. In this function you will take one argument 'num'\n",
    "2. This 'num' is a shared Memory of type 'value' and is to be declared as 'double'.\n",
    "3. You just have to assign a real number to the 'num' variable inside the function and get it printed \n",
    "  in the 'if statement' (if __name_ == \"__main__\")\n",
    "4. We have added multiprocessing.active_children() for you in the bottom of code which prints number of active workers.\n",
    "5. You job is to just add 1 line of code to get the numbers of CPU in the system.(There is a inbulit function for this).\n",
    "\n",
    "'''\n",
    "import multiprocessing\n",
    "from multiprocessing import Value\n",
    "\n",
    "class Task7():\n",
    "    \n",
    "    def getSquares(numbers, result):    \n",
    "          for index, num in enumerate(numbers):\n",
    "                result[index] = num*num\n",
    "          eval = result\n",
    "          return eval\n",
    "    def getNumsquare(num):\n",
    "         num.value=random.randint(10,20)\n",
    "         return num\n",
    "\n",
    "    if __name__ == \"__main__\":\n",
    "          numbers = [2,3,5]\n",
    "          result = []\n",
    "          num=multiprocessing.Value('d',1.0)\n",
    "          ###  COMMENT FOUR LINES BELOW  ####\n",
    "          result = multiprocessing.Array('i', 3)\n",
    "          p = multiprocessing.Process(target=getSquares, args=(numbers, result))\n",
    "          q = multiprocessing.Process(target=getNumsquare, args=(num,))\n",
    "          p.start()\n",
    "          q.start()\n",
    "          p.join()\n",
    "          q.join()\n",
    "       \n",
    "           #### THE FOUR LINES TO BE COMMENTED   #######\n",
    "\n",
    "          print(multiprocessing.active_children())\n",
    "          print(result[:])\n",
    "          print(num.value)\n",
    "Task7()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
